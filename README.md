# ğŸ”¬ Patent Analysis Pipeline with LightRAG

An intelligent patent analysis system that combines **LightRAG (Retrieval-Augmented Generation)**, vector embeddings, and AI to analyze G06 (computer technology) patents with semantic understanding.

## ğŸš€ Features

- **LightRAG Integration**: Advanced RAG system with knowledge graph
- **Vector Database**: Fast semantic similarity search with NanoVectorDB
- **Neo4j Graph Storage**: Persistent knowledge graph for patent relationships
- **AI-Powered Chatbot**: Interactive interface for patent queries with enhanced UX
- **Sequential Processing**: Safe, one-at-a-time document processing
- **Persistent Storage**: Data survives server restarts
- **Optimized Documents**: 90-99% size reduction for efficient processing
- **Real-time Streaming**: Live responses from the chatbot
- **Backup System**: Automatic SQLite backup of LightRAG data
- **Neo4j Fallback**: Direct Neo4j query capability when LightRAG is down
- **Multi-Layer Storage**: JSON files + SQLite backup + Neo4j graph
- **Data Recovery**: Multiple recovery scenarios and query methods
- **Grafana + PostgreSQL Monitoring**: Real-time performance metrics and dashboards
- **Guardrails System**: Content safety and quality checks
- **Evaluation Metrics**: ROUGE, relevance, and coherence scoring
- **Enhanced User Experience**: Input validation, field categorization, and improved UI
- **Smart Patent Analysis**: RAG-powered prior art search and invention evaluation
- **Enhanced Patent Search**: Exact match logic with internet search fallback
- **Improved Follow-up System**: Context-aware responses with 3-option menu
- **Optimized Timeouts**: 5-minute timeouts for complex internet search + LLM processing
- **OpenAI Integration**: GPT-4o-mini fallback for current patent information
- **Hybrid Search Strategy**: RAG â†’ OpenAI â†’ Local LLM fallback chain
- **Smart Query Expansion**: Intelligent synonym and abbreviation handling for better search results

## ğŸ†• Latest Improvements

### **Smart Query Expansion System** ğŸ†•
- **Technology Synonyms**: Comprehensive mapping of technology terms and their variations
- **Abbreviation Resolution**: Automatic expansion of common abbreviations (IoT â†’ Internet of Things, AI â†’ Artificial Intelligence)
- **Multi-Term Search**: Enhanced search using multiple related terms for better coverage
- **Intelligent Fallback**: RAG database search with internet search fallback using expanded terms

**Supported Technology Mappings:**
- **IoT**: Internet of Things, connected devices, smart devices, wireless sensors
- **AI/ML**: Artificial Intelligence, Machine Learning, deep learning, neural networks
- **Blockchain**: Distributed ledger, DLT, cryptocurrency, smart contracts
- **5G**: Fifth generation wireless, mobile broadband, wireless communication
- **Cloud Computing**: SaaS, software as a service, virtualization, distributed computing
- **And many more...**

**How It Works:**
1. **Query Preprocessing**: Expands abbreviations and identifies synonyms
2. **Multi-Term Generation**: Creates 5-10 related search terms
3. **RAG Search**: Tries original query first, then expanded terms
4. **Internet Search**: Uses multiple terms for comprehensive internet search
5. **Deduplication**: Removes duplicate results across search terms
6. **Enhanced Analysis**: LLM processes combined results for comprehensive analysis

### **Enhanced User Experience**
- **Input Validation**: Menu options validated with user-friendly error messages
- **Length Validation**: Title (10+ chars) and Abstract (50+ chars) minimum requirements
- **Smart Field Selection**: Top 10 G06N/G06V technology categories with multi-select
- **Improved Gradio Interface**: Send button, better organization, and field selection panel
- **Enhanced RAG Integration**: All patent analysis now uses RAG for prior art search

### **Patent Field Categories** (Based on G06N/G06V Analysis)
1. **Machine Learning & AI**
2. **Computer Vision & Image Processing**
3. **Neural Networks & Deep Learning**
4. **Pattern Recognition & Classification**
5. **Data Mining & Analytics**
6. **Bioinformatics & Computational Biology**
7. **Natural Language Processing**
8. **Robotics & Automation**
9. **Signal Processing & Audio**
10. **Others (search all patents)**

### **Smart Validation System**
- **Menu Options**: Invalid selections â†’ re-prompt with options
- **Text Length**: Short inputs â†’ user-friendly error messages
- **Description Selection**: Y/N validation with re-prompting
- **Field Selection**: Multi-select with validation and "Others" option

### **Enhanced Patent Analysis Flow**
- **New Invention Analysis**: Step-by-step collection with validation
- **Existing Patent Analysis**: RAG-enhanced with prior art search
- **Patent Search**: Field-specific queries with comprehensive results
- **RAG Integration**: All analysis uses LightRAG for context and prior art

## ğŸ“ Project Structure

```
patent_project/
â”œâ”€â”€ main.py                          # Main orchestration script
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ .env                            # LightRAG configuration
â”‚
â”œâ”€â”€ filtering/                       # Step 1: Patent Filtering
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ filter_g06_patents_optimized.py
â”‚
â”œâ”€â”€ lightrag_integration/            # Step 2: LightRAG Integration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ lightrag_config.py
â”‚   â”œâ”€â”€ start_lightrag_server.py
â”‚   â””â”€â”€ integrate_lightrag_g06_patents_sequential.py
â”‚
â”œâ”€â”€ chatbot/                         # Step 3: Interactive Chatbot
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ patent_chatbot.py
â”‚   â”œâ”€â”€ query_expansion.py          # Smart query expansion and synonym handling
â”‚   â”œâ”€â”€ neo4j_fallback.py           # Neo4j fallback for LightRAG
â”‚   â””â”€â”€ guardrails_validator.py     # Content safety validation
â”‚
â”œâ”€â”€ monitoring/                      # Performance Monitoring
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ postgres_monitor.py         # PostgreSQL monitoring system
â”‚   â”œâ”€â”€ simple_postgres_dashboard.json # Grafana dashboard config
â”‚   â”œâ”€â”€ test_postgres_monitoring.py # PostgreSQL monitoring tests
â”‚   â”œâ”€â”€ verify_monitoring_flow.py   # Monitoring flow verification
â”‚   â””â”€â”€ README.md                   # Monitoring documentation
â”‚
â”œâ”€â”€ backup/                          # Backup System
â”‚   â”œâ”€â”€ manage_backup.py            # Backup system management
â”‚   â”œâ”€â”€ backup_query_tool.py        # Query backed up data
â”‚   â”œâ”€â”€ lightrag_backup_monitor.py  # Backup monitoring system
â”‚   â””â”€â”€ test_neo4j_backup.py       # Neo4j backup tests
â”‚
â”œâ”€â”€ evaluation/                      # Evaluation Metrics
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ evaluate_responses.py       # Response evaluation system
â”‚
â”œâ”€â”€ hupd_extracted/                  # Source patent data
â”œâ”€â”€ hupd_processed/                  # Filtered and optimized G06 patents
â”œâ”€â”€ lightrag_upload/                 # Files ready for LightRAG upload
â”œâ”€â”€ lightrag_storage/                # LightRAG persistent storage
â””â”€â”€ lightrag_backup.db               # Backup SQLite database
```

## ğŸ”„ Pipeline Flow

### 1. **Filtering** (`filtering/`)
- **Purpose**: Extract and optimize G06 patents from source data
- **Input**: Raw patent data from `hupd_extracted/`
- **Output**: Filtered and optimized patents in `hupd_processed/`
- **Script**: `filter_g06_patents_optimized.py`

### 2. **LightRAG Integration** (`lightrag_integration/`)
- **Purpose**: Start LightRAG server and integrate patents
- **Input**: Filtered and optimized patents from `hupd_processed/`
- **Output**: Patents indexed in LightRAG knowledge base
- **Scripts**: 
  - `lightrag_config.py` - Configuration management
  - `start_lightrag_server.py` - Server startup
  - `integrate_lightrag_g06_patents_sequential.py` - Patent integration

### 3. **Chatbot** (`chatbot/`)
- **Purpose**: Interactive interface for querying patents
- **Input**: LightRAG knowledge base
- **Output**: Web interface for patent queries
- **Script**: `patent_chatbot.py`

## ğŸ“‹ Prerequisites

- Python 3.10+
- Ollama (for LLM models)
- Neo4j Database (local installation)
- 16GB+ RAM (for LLM model and vector operations)
- GPU recommended (for faster LLM inference)

## ğŸ› ï¸ Installation

### 1. **Clone and Setup**
```bash
git clone <repository-url>
cd patent_project
```

### 2. **Create Virtual Environment**
```bash
# Create virtual environment
python -m venv lightrag_env

# Activate virtual environment
source lightrag_env/bin/activate  # On macOS/Linux
# or
lightrag_env\Scripts\activate     # On Windows
```

### 3. **Install Dependencies**
```bash
# Install Python dependencies
pip install -r requirements.txt

# Install additional dependencies
pip install gradio requests
```

### 4. **Ollama Setup**
```bash
# Install Ollama (if not already installed)
# Visit: https://ollama.ai/

# Pull required models
ollama pull qwen2.5:14b-instruct
ollama pull bge-m3:latest
```

### 5. **Neo4j Setup**
```bash
# Install Neo4j (macOS)
brew install neo4j

# Start Neo4j service
brew services start neo4j

# Set password (default: password)
cypher-shell -u neo4j -p neo4j "ALTER CURRENT USER SET PASSWORD FROM 'neo4j' TO 'password'"
```

### 6. **LightRAG (Optional)**
If you want to use the LightRAG CLI for server management:

```bash
# Install Rust (required for LightRAG)
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Install LightRAG
pip install lightrag
```

**Note**: The pipeline works without LightRAG CLI installation. You can start the LightRAG server manually if needed.

## ğŸ›¡ï¸ Guardrails & Evaluation Metrics

### Guardrails (Chatbot Safety & Quality)
- **Profanity Check**: Ensures responses are free of offensive language.
- **Restrict to Topic**: Keeps answers focused on patents, intellectual property, and technology.
- **Politeness Check**: Maintains a professional and respectful tone.

**How to Use:**
- **Interactive Menu:** When you select "Run interactive chatbot", youâ€™ll be prompted:
  - `Enable guardrails? (Y/n):` â€” Press Enter or type `y` to enable, `n` to disable.
- **Command Line:**
  - Enable guardrails (default):
    ```bash
    python main.py --mode chat
    ```
  - Disable guardrails:
    ```bash
    python main.py --mode chat --no-guardrails
    ```

**What You See:**
- When enabled, every chatbot response is checked and scored for:
  - Profanity (0.0 = clean, 1.0 = profanity detected)
  - Topic relevance (0.0 = on-topic, 1.0 = off-topic)
  - Politeness (0.0 = polite, 1.0 = impolite)
- **Interpretation:** For all guardrails, a score of **1.0** means the guardrail was triggered (bad), and **0.0** means no issue (good).
- Scores are shown in the CLI and batch evaluation reports.
- When disabled, responses are not filtered or scored for these guardrails.

### Evaluation Metrics
- **ROUGE-1, ROUGE-2, ROUGE-L**: Measures n-gram and sequence overlap with reference answers.
- **Relevance Score**: Semantic similarity between the query and the response.
- **Coherence Score**: Measures text quality and structure.
- **Guardrails Scores**: Profanity, topic relevance, and politeness (see above).
- **Batch Reports**: Show averages and per-response scores for all metrics.

## ğŸš€ Quick Start

### Option 1: Interactive Mode
```bash
# Activate virtual environment
source lightrag_env/bin/activate

# Run interactive pipeline
python main.py
```

### Option 2: Full Pipeline
```bash
# Run complete pipeline
python main.py --mode full
```

### Option 3: Step-by-Step
```bash
# Check dependencies
python main.py --mode check

# Filter patents
python main.py --mode filter --input-dir hupd_extracted

# Integrate patents
python main.py --mode integrate

# Launch chatbot (with guardrails) - Only CLI
python main.py --mode chat
# Launch chatbot (without guardrails) - Only CLI
python main.py --mode chat --no-guardrails

# Launch chatbot (without guardrails) - Gradio
python main.py --mode chat --web-interface

```

## ğŸ® Usage Modes

### Interactive Mode
```bash
python main.py
```
Provides a menu-driven interface:
- When launching the chatbot, you can enable or disable guardrails for that session.

### Command Line Modes
```bash
# Check system status
python main.py --mode check

# Filter patents
python main.py --mode filter --input-dir hupd_extracted

# Start LightRAG server (if CLI available)
python main.py --mode start-server

# Integrate patents
python main.py --mode integrate

# Test chatbot
python main.py --mode test

# Launch chatbot interface
python main.py --mode chat

# Run full pipeline
python main.py --mode full --input-dir hupd_extracted
```

## ğŸ® Chatbot Features

### **Core Features**
- **Guardrails Toggle**: Enable or disable safety checks for profanity, topic, and politeness
- **Streaming Responses**: Real-time text generation
- **Error Handling**: Graceful handling of timeouts and connection issues
- **Status Panel**: Live system status monitoring
- **Example Queries**: Click-to-use example questions
- **Clear Chat**: Reset conversation history

### **Enhanced User Experience** ğŸ†•
- **Input Validation**: Menu options validated with user-friendly error messages
- **Length Validation**: Title (10+ chars) and Abstract (50+ chars) minimum requirements
- **Smart Field Selection**: Top 10 G06N/G06V technology categories with multi-select
- **Improved Gradio Interface**: Send button, better organization, and field selection panel
- **Enhanced RAG Integration**: All patent analysis now uses RAG for prior art search

### **Patent Analysis Capabilities** ğŸ†•
- **New Invention Analysis**: Step-by-step collection with validation and RAG-powered prior art search
- **Existing Patent Analysis**: RAG-enhanced with comprehensive prior art analysis
- **Patent Search**: Field-specific queries with comprehensive results
- **Field Categories**: 10 technology categories based on G06N/G06V analysis
- **"Others" Category**: Searches all patent nodes when selected

### **Smart Validation System** ğŸ†•
- **Menu Options**: Invalid selections â†’ re-prompt with options
- **Text Length**: Short inputs â†’ user-friendly error messages (no character counts)
- **Description Selection**: Y/N validation with re-prompting
- **Field Selection**: Multi-select with validation and "Others" option

### **RAG-Powered Analysis** ğŸ†•
- **Prior Art Search**: All patent analysis uses LightRAG for context
- **Field-Specific Queries**: RAG queries include selected technology fields
- **Comprehensive Results**: Combines RAG context with local analysis
- **Fallback Systems**: SQLite and Neo4j fallbacks when LightRAG is unavailable

### **Enhanced Patent Search with Internet Fallback** ğŸ†•
- **Exact Match Logic**: Searches for exact patent numbers or titles in RAG database
- **Internet Search Fallback**: When no exact match found, performs internet search for patent information
- **Smart Response Generation**: LLM processes internet data to provide comprehensive patent analysis
- **Timeout Optimization**: 5-minute timeouts for complex internet search + LLM processing
- **Response Differentiation**: Clear indication of whether RAG or internet search was used

### **Improved Follow-up Menu System** ğŸ†•
- **"Need More Details"**: Interactive query flow - prompts user for specific questions, generates LLM responses, and continues until user says no
- **"Return to Main Menu"**: Properly resets conversation state and shows original options
- **"Search for Different Patent"**: Starts a new patent search session
- **Context-Aware Responses**: Follow-up questions answered based on previous search context
- **Follow-up Count Tracking**: Maximum 5 follow-up questions before auto-return to menu
- **Conversation State Management**: Maintains context throughout the interaction

### **Interactive Query Flow** ğŸ†•
When users select "Need more details about this patent":
1. **Prompt for Query**: System asks "Please provide your query"
2. **LLM Response**: Generates response using LLM (not RAG+LLM)
3. **Continue Loop**: Asks "Do you have any further questions? (yes/no)"
4. **Yes**: Returns to step 1 (prompt for new query)
5. **No**: Returns to main menu
6. **Invalid Input**: Prompts for yes/no response

### **Patent Search Flow** ğŸ†•
1. **Exact Search**: User provides patent number/title â†’ System searches RAG database for exact match
2. **Match Found**: If exact match exists â†’ Uses RAG data for comprehensive analysis
3. **No Match**: If no exact match â†’ Triggers internet search for patent information
4. **Internet Analysis**: LLM processes internet data to provide detailed patent analysis
5. **Follow-up Options**: User gets 3 options: "Need more details", "Return to menu", "Search different patent"
6. **Context Continuation**: Follow-up questions maintain search context for detailed responses

### **OpenAI Integration & Hybrid Search Strategy** ğŸ†•
- **GPT-4o-mini Integration**: Access to current patent information beyond training data cutoff
- **Hybrid Search Chain**: RAG â†’ OpenAI â†’ Local LLM fallback for maximum coverage
- **Cost Optimization**: Caching and token management to minimize API costs
- **Response Attribution**: Clear indication of data source (RAG, OpenAI, or Local LLM)
- **Error Handling**: Graceful fallback when OpenAI is unavailable

### **OpenAI Configuration** ğŸ†•
```bash
# Add to .env file
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini
OPENAI_TIMEOUT=60
OPENAI_MAX_TOKENS=4000
OPENAI_TEMPERATURE=0.1
ENABLE_OPENAI_FALLBACK=true
OPENAI_CACHE_ENABLED=true
OPENAI_CACHE_DURATION=3600
```

## ğŸ” Smart Query Expansion Examples

### **How Query Expansion Works**
The system automatically expands your search queries to find more relevant patents:

**Example 1: IoT Search**
- **Your Input**: "IoT"
- **Expanded Terms**: "Internet of Things", "connected devices", "smart devices", "wireless sensors", "smart home", "industrial IoT", "edge computing"
- **Result**: Comprehensive search across all related terms

**Example 2: AI/ML Search**
- **Your Input**: "machine learning"
- **Expanded Terms**: "ML", "AI", "artificial intelligence", "deep learning", "neural networks", "predictive analytics", "data science"
- **Result**: Finds patents using various AI/ML terminology

**Example 3: Blockchain Search**
- **Your Input**: "blockchain"
- **Expanded Terms**: "distributed ledger", "DLT", "cryptocurrency", "smart contracts", "decentralized", "Web3", "DeFi"
- **Result**: Comprehensive blockchain technology coverage

### **Supported Abbreviations**
The system automatically expands common abbreviations:
- **IoT** â†’ Internet of Things
- **AI** â†’ Artificial Intelligence  
- **ML** â†’ Machine Learning
- **AR** â†’ Augmented Reality
- **VR** â†’ Virtual Reality
- **5G** â†’ Fifth Generation Wireless
- **SaaS** â†’ Software as a Service
- **API** â†’ Application Programming Interface

### **Search Strategy**
1. **Original Query**: Searches with your exact input first
2. **RAG Database**: Checks LightRAG for relevant patents
3. **Expanded Terms**: Uses 5-10 related terms for comprehensive search
4. **Internet Search**: Falls back to Google Patents with expanded terms
5. **Deduplication**: Removes duplicate results across all searches
6. **Enhanced Analysis**: LLM processes combined results for comprehensive analysis

## ğŸ® Usage Modes

### Interactive Mode
```bash
python main.py
```
Provides a menu-driven interface:
- When launching the chatbot, you can enable or disable guardrails for that session.

### Command Line Modes
```bash
# Check system status
python main.py --mode check

# Filter patents
python main.py --mode filter --input-dir hupd_extracted

# Start LightRAG server (if CLI available)
python main.py --mode start-server

# Integrate patents
python main.py --mode integrate

# Test chatbot
python main.py --mode test

# Launch chatbot interface
python main.py --mode chat

# Run full pipeline
python main.py --mode full --input-dir hupd_extracted
```

## ğŸ› ï¸ Configuration

### LightRAG Configuration
- **Server**: localhost:9621
- **Model**: qwen2.5:14b-instruct
- **Embedding**: bge-m3:latest
- **Storage**: Neo4j + JSON + Vector DB
- **Max Graph Nodes**: 10,000 (configurable)

### Environment Variables (.env)
```bash
# LightRAG Configuration
MAX_GRAPH_NODES=10000
HOST=0.0.0.0
PORT=9621
WORKING_DIR=./rag_storage
INPUT_DIR=./lightrag_upload

# LLM Configuration
LLM_BINDING=ollama
LLM_BINDING_HOST=http://localhost:11434
LLM_MODEL=qwen2.5:14b-instruct

# Embedding Configuration
EMBEDDING_BINDING=ollama
EMBEDDING_BINDING_HOST=http://localhost:11434
EMBEDDING_MODEL=bge-m3:latest

# Performance Settings
MAX_TOKENS=32768
MAX_ASYNC=4
TIMEOUT=300

# Search Parameters
TOP_K=60
COSINE_THRESHOLD=0.2

# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password
NEO4J_DATABASE=lightrag_patents
```

## ğŸ’¾ Storage Architecture & Backup System

### **Multi-Layer Storage Architecture**

The system uses a sophisticated multi-layer storage approach to ensure data persistence and availability:

#### **1. LightRAG Primary Storage** (JSON Files)
- **Location**: `lightrag_storage/` directory
- **Files**: 
  - `kv_store_full_docs.json` - Complete patent documents
  - `kv_store_text_chunks.json` - Document text chunks
  - `kv_store_doc_status.json` - Processing status
  - `vdb_chunks.json` - Vector embeddings
  - `vdb_entities.json` - Entity data
  - `vdb_relationships.json` - Entity relationships
- **Backup Frequency**: Real-time (every document processed)
- **Status**: âœ… **Primary data storage**

#### **2. SQLite Backup Database** (Automatic Backup)
- **Location**: `lightrag_backup.db`
- **Purpose**: Secondary backup of all LightRAG data
- **Tables**:
  - `full_docs` - Complete patent documents
  - `text_chunks` - Document text chunks  
  - `doc_status` - Processing status
  - `backup_log` - Backup activity log
- **Backup Frequency**: Every 30 seconds (when changes detected)
- **Status**: âœ… **Automatic backup system**

#### **3. Neo4j Graph Storage** (Entity Relationships)
- **Location**: `bolt://localhost:7687`
- **Purpose**: Entity relationship graph
- **Node Types**: 
  - `document` - Patent documents (25 nodes)
  - `base` - Base entities (6,000+ nodes)
  - `category` - Patent categories
  - `organization` - Companies/institutions
  - `person` - Inventors/assignees
- **Status**: âœ… **Entity relationship storage**

### **Backup System Architecture**

#### **LightRAG Backup Monitor** (`lightrag_backup_monitor.py`)
```python
# Features:
- Non-intrusive file monitoring
- MD5 hash change detection
- Automatic SQLite backup
- Real-time statistics
- Thread-safe operation
```

#### **Backup Process Flow**
1. **Monitor**: Watches `lightrag_storage/*.json` files
2. **Detect**: Uses file hashes to detect changes
3. **Backup**: Copies data to SQLite database
4. **Log**: Records all backup activities
5. **Repeat**: Every 30 seconds

#### **Backup Database Schema**
```sql
-- Full Documents Table
CREATE TABLE full_docs (
    doc_id TEXT PRIMARY KEY,
    content TEXT,
    last_updated TIMESTAMP,
    file_hash TEXT
);

-- Text Chunks Table  
CREATE TABLE text_chunks (
    chunk_id TEXT PRIMARY KEY,
    content TEXT,
    doc_id TEXT,
    last_updated TIMESTAMP,
    file_hash TEXT
);

-- Document Status Table
CREATE TABLE doc_status (
    doc_id TEXT PRIMARY KEY,
    status TEXT,
    last_updated TIMESTAMP,
    file_hash TEXT
);

-- Backup Log Table
CREATE TABLE backup_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp TIMESTAMP,
    action TEXT,
    file_name TEXT,
    records_count INTEGER,
    status TEXT
);
```

### **Neo4j Integration & Fallback System**

#### **Neo4j Fallback** (`chatbot/neo4j_fallback.py`)
The system includes a sophisticated fallback mechanism that allows the chatbot to query Neo4j directly when LightRAG is unavailable:

```python
# Features:
- Direct Neo4j connection
- Document search capabilities
- Entity relationship queries
- Automatic fallback activation
- Error handling and recovery
```

#### **Fallback Query Capabilities**
```cypher
-- Search documents by content
MATCH (d:document)
WHERE d.description CONTAINS $search_term 
   OR d.file_path CONTAINS $search_term
RETURN d.entity_id as id, d.file_path as title, d.description as content

-- Get document statistics
MATCH (d:document)
RETURN count(d) as total_documents

-- Find entity relationships
MATCH (d:document)-[r]-(related:document)
RETURN d.entity_id, related.entity_id, type(r) as relationship
```

#### **Fallback Activation**
The chatbot automatically switches to Neo4j fallback when:
- LightRAG server is down
- LightRAG request times out
- LightRAG returns an error
- Network connectivity issues

#### **SQLite Backup Fallback** (`chatbot/sqlite_fallback.py`)
The system includes a comprehensive SQLite backup that provides a third-tier fallback when both LightRAG and Neo4j are unavailable:

```python
# Features:
- Complete document backup in SQLite database (lightrag_backup.db)
- Full-text search capabilities on 2,211+ documents
- Document and chunk-level queries with timestamps
- Automatic backup monitoring every 30 seconds
- Direct SQLite query interface
```

#### **Three-Tier Fallback System**
1. **LightRAG** (Primary): Full RAG capabilities with vector search and LLM integration
2. **SQLite Backup** (Secondary): Complete document backup with full-text search
3. **Neo4j** (Tertiary): Graph-based entity relationships and document metadata

#### **SQLite Fallback Query Capabilities**
```sql
-- Search documents by content
SELECT doc_id, content, last_updated 
FROM full_docs 
WHERE content LIKE '%machine learning%' 
ORDER BY last_updated DESC 
LIMIT 10;

-- Search text chunks
SELECT chunk_id, content, doc_id, last_updated 
FROM text_chunks 
WHERE content LIKE '%neural network%' 
ORDER BY last_updated DESC 
LIMIT 10;

-- Get backup statistics
SELECT 
    COUNT(*) as total_docs,
    MAX(last_updated) as last_backup
FROM full_docs;
```

#### **SQLite Fallback Testing**
```bash
# Test SQLite fallback functionality
python test_sqlite_fallback.py

# Test from main menu
python main.py
# Select option 12: "Test SQLite fallback"

# Expected output:
# âœ… SQLite backup database connected successfully
#    Documents: 2211
#    Chunks: 2211
#    Last backup: 2025-07-13T16:56:38.298655
```

### **Data Retrieval Methods**

#### **1. LightRAG Primary Query** (Preferred)
```bash
# Normal operation - queries LightRAG server
curl -X POST http://localhost:9621/api/chat \
  -H "Content-Type: application/json" \
  -d '{"model": "qwen2.5:14b-instruct", "messages": [{"role": "user", "content": "Find patents about machine learning"}]}'
```

#### **2. SQLite Backup Query** (Backup Data)
```bash
# Query backed up data directly
python backup_query_tool.py

# Or programmatically:
from backup_query_tool import BackupQueryTool
tool = BackupQueryTool()
results = tool.search_documents("machine learning", limit=10)
```

#### **3. Neo4j Fallback Query** (Entity Relationships)
```bash
# Direct Neo4j queries
cypher-shell -u neo4j -p password "
MATCH (d:document)
WHERE d.description CONTAINS 'machine learning'
RETURN d.entity_id, d.file_path, d.description
LIMIT 10
"
```

### **Backup System Management**

#### **Start Backup Monitoring**
```bash
# Interactive management
python manage_backup.py

# Direct start
python lightrag_backup_monitor.py
```

#### **Query Backup Data**
```bash
# Interactive query tool
python backup_query_tool.py

# Quick stats
python -c "
from backup_query_tool import BackupQueryTool
tool = BackupQueryTool()
stats = tool.get_stats()
print(f'Documents: {stats[\"full_docs_count\"]}')
print(f'Chunks: {stats[\"text_chunks_count\"]}')
print(f'Last Backup: {stats[\"last_backup\"]}')
"
```

#### **Backup Statistics**
```bash
# Check backup status
python manage_backup.py
# Select option 3: Show backup statistics

# Expected output:
# ğŸ“Š Backup Statistics:
#    Full Documents: 1,935
#    Text Chunks: 1,935  
#    Document Status: 2,755
#    Last Backup: 2025-07-12T23:15:09.591492
```

### **Data Recovery Scenarios**

#### **Scenario 1: LightRAG Server Down**
```bash
# Chatbot automatically uses Neo4j fallback
python main.py --mode chat
# Query: "Find patents about AI"
# Response: Uses Neo4j document nodes (25 available)
```

#### **Scenario 2: Complete System Failure**
```bash
# Restore from SQLite backup
python backup_query_tool.py
# Search: "machine learning patents"
# Results: All backed up documents available
```

#### **Scenario 3: File Corruption**
```bash
# Rebuild from backup database
python -c "
import sqlite3
conn = sqlite3.connect('lightrag_backup.db')
cursor = conn.cursor()
cursor.execute('SELECT COUNT(*) FROM full_docs')
print(f'Available documents: {cursor.fetchone()[0]}')
"
```

### **Performance & Monitoring**

#### **Backup Performance**
- **Monitoring Interval**: 30 seconds
- **File Change Detection**: MD5 hash comparison
- **Backup Speed**: ~1000 documents/second
- **Storage Overhead**: Minimal (SQLite compression)

#### **System Health Monitoring**
```bash
# Check all storage systems
python -c "
from chatbot.neo4j_fallback import Neo4jFallback
from backup_query_tool import BackupQueryTool

# Neo4j status
neo4j = Neo4jFallback()
neo4j_result = neo4j.test_connection()

# Backup status  
backup = BackupQueryTool()
backup_stats = backup.get_stats()

print(f'Neo4j: {neo4j_result[\"document_count\"]} documents')
print(f'Backup: {backup_stats[\"full_docs_count\"]} documents')
print(f'LightRAG: Processing {neo4j_result[\"document_count\"]} documents')
"
```

### **Troubleshooting Storage Issues**

#### **If Backup Not Working**
```bash
# Check backup monitor status
ps aux | grep lightrag_backup_monitor

# Restart backup monitor
python manage_backup.py
# Select option 1: Start backup monitor
```

#### **If Neo4j Empty**
```bash
# Check Neo4j connection
cypher-shell -u neo4j -p password "RETURN 1"

# Check entity nodes
cypher-shell -u neo4j -p password "MATCH (n) RETURN labels(n), count(n)"
```

#### **If LightRAG Files Missing**
```bash
# Check LightRAG storage
ls -la lightrag_storage/

# Check backup database
ls -la lightrag_backup.db

# Restore from backup if needed
python backup_query_tool.py
```

## ğŸ“Š Performance Monitoring & Grafana Integration

### **Comprehensive Monitoring System**

The patent analysis pipeline includes a sophisticated monitoring system that tracks performance metrics, system health, and user experience in real-time.

#### **What We Monitor**

##### **Response Performance**
- **Response Time**: Average, 95th percentile, max response times
- **Throughput**: Requests per minute/second
- **Success Rate**: Percentage of successful vs failed requests
- **Timeout Rate**: Percentage of requests that timeout

##### **Model Performance**
- **Token Usage**: Input/output tokens per request
- **Model Latency**: Time spent in LLM inference
- **Model Accuracy**: Guardrails scores (profanity, topic, politeness)
- **Evaluation Metrics**: ROUGE, relevance, coherence scores

##### **System Health**
- **LightRAG Server Status**: Health checks, uptime
- **Neo4j Database**: Connection status, query performance
- **Ollama Service**: Model availability, memory usage
- **Resource Usage**: CPU, memory, disk I/O

##### **User Experience**
- **Active Sessions**: Number of concurrent users
- **Query Patterns**: Most common questions, query length
- **User Satisfaction**: Based on guardrails scores
- **Error Types**: Timeout, connection, validation errors

##### **Business Metrics**
- **Patent Coverage**: Number of patents indexed
- **Query Volume**: Daily/weekly/monthly trends
- **Popular Topics**: Most queried patent categories
- **System Utilization**: Peak usage times

### **Grafana Dashboard Setup**

#### **1. Install Grafana**
```bash
# macOS
brew install grafana

# Start Grafana
brew services start grafana

# Access Grafana
# Open http://localhost:3000
# Default credentials: admin/admin
```

#### **2. Import Dashboard**
```bash
# Copy dashboard configuration
cp monitoring/grafana_dashboard.json /tmp/

# Import in Grafana:
# 1. Go to Dashboards â†’ Import
# 2. Upload the JSON file
# 3. Configure data source
# 4. Save dashboard
```

#### **3. Dashboard Panels**

The Grafana dashboard includes these key panels:

1. **Response Performance**: Average response time
2. **Success Rate**: Percentage of successful requests
3. **Response Time Distribution**: P95 and P50 response times
4. **System Health**: LightRAG, Neo4j, Ollama status
5. **Resource Usage**: CPU, memory, disk usage
6. **Guardrails Performance**: Profanity, topic, politeness scores
7. **Active Sessions**: Current user sessions
8. **Token Usage**: Average tokens per request
9. **Query Categories**: Distribution of query types
10. **Error Rate**: Request error frequency

### **Monitoring Configuration**

#### **Enable Monitoring in Chatbot**
```bash
# Interactive mode with monitoring
python main.py
# Select option 3 (Run interactive chatbot)
# Enable monitoring when prompted
```

#### **View Real-time Dashboard**
```bash
# From the main menu, select option 9
# "Show monitoring dashboard"
```

#### **Save Monitoring Data**
```bash
# From the main menu, select option 10
# "Save monitoring data"
```

### **Monitoring Commands**

#### **Start Monitoring**
```bash
# Enable monitoring during chatbot startup
python main.py --mode chat --enable-monitoring

# Or interactively
python main.py
# Select option 3: Run interactive chatbot
# Enable monitoring when prompted
```

#### **View Monitoring Dashboard**
```bash
# Access Grafana dashboard
open http://localhost:3000

# Or from main menu
python main.py
# Select option 9: Show monitoring dashboard
```

#### **Export Monitoring Data**
```bash
# Save monitoring data to file
python main.py
# Select option 10: Save monitoring data

# Or programmatically
python -c "
from monitoring.chatbot_monitor import ChatbotMonitor
monitor = ChatbotMonitor()
data = monitor.get_monitoring_data()
print(f'Response metrics: {len(data[\"response_metrics\"])}')
print(f'System health: {len(data[\"system_health\"])}')
"
```

#### **Check Monitoring Status**
```bash
# Check if monitoring is active
python -c "
from monitoring.chatbot_monitor import ChatbotMonitor
monitor = ChatbotMonitor()
stats = monitor.get_monitoring_stats()
print(f'Active monitoring: {stats[\"monitoring_active\"]}')
print(f'Total responses: {stats[\"total_responses\"]}')
print(f'Average response time: {stats[\"avg_response_time\"]:.2f}s')
"
```

### **Monitoring Data Retention**

- **Response Metrics**: Last 10,000 responses
- **System Health**: Last 1,000 health checks
- **Business Metrics**: Last 100 snapshots
- **Performance Data**: Rolling 1,000 samples

### **Health Check Frequency**

- **System Health**: Every 30 seconds
- **Business Metrics**: Every 5 minutes (10 health checks)

### **Grafana Dashboard Configuration**

#### **Dashboard JSON Structure**
```json
{
  "dashboard": {
    "title": "Patent Chatbot Monitoring",
    "panels": [
      {
        "title": "Response Performance",
        "type": "graph",
        "targets": [
          {
            "expr": "avg(response_time)",
            "legendFormat": "Average Response Time"
          }
        ]
      },
      {
        "title": "Success Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "success_rate",
            "legendFormat": "Success Rate %"
          }
        ]
      }
    ]
  }
}
```

#### **Key Metrics Tracked**
```python
# Response Performance
response_time_avg = "Average response time in seconds"
response_time_p95 = "95th percentile response time"
success_rate = "Percentage of successful requests"
timeout_rate = "Percentage of timed out requests"

# System Health
lightrag_status = "LightRAG server health (0/1)"
neo4j_status = "Neo4j database health (0/1)"
ollama_status = "Ollama service health (0/1)"
cpu_usage = "CPU usage percentage"
memory_usage = "Memory usage percentage"

# Guardrails Performance
profanity_score = "Average profanity score (0-1)"
topic_score = "Average topic relevance score (0-1)"
politeness_score = "Average politeness score (0-1)"

# Business Metrics
active_sessions = "Number of active user sessions"
total_queries = "Total queries processed"
popular_topics = "Most queried patent categories"
```

### **Monitoring Alerts**

#### **Alert Configuration**
```bash
# Set up alerts in Grafana
# 1. Go to Alerting â†’ Alert Rules
# 2. Create new alert rule
# 3. Configure thresholds:
#    - Response time > 10 seconds
#    - Success rate < 90%
#    - System health = 0
#    - Memory usage > 80%
```

#### **Alert Channels**
- **Email**: Send alerts to admin email
- **Slack**: Post to monitoring channel
- **Webhook**: Custom webhook integration
- **PagerDuty**: Incident management

### **Performance Baselines**

#### **Expected Performance Metrics**
- **Response Time**: < 5 seconds (average)
- **Success Rate**: > 95%
- **System Uptime**: > 99%
- **Memory Usage**: < 80%
- **CPU Usage**: < 70%

#### **Guardrails Score Targets**
- **Profanity Score**: > 0.9 (clean responses)
- **Topic Score**: > 0.8 (relevant responses)
- **Politeness Score**: > 0.8 (professional tone)

### **Troubleshooting Monitoring**

#### **If Grafana Not Loading**
```bash
# Check Grafana service
brew services list | grep grafana

# Restart Grafana
brew services restart grafana

# Check logs
tail -f /usr/local/var/log/grafana/grafana.log
```

#### **If Monitoring Data Missing**
```bash
# Check monitoring is enabled
python -c "
from monitoring.chatbot_monitor import ChatbotMonitor
monitor = ChatbotMonitor()
print(f'Monitoring active: {monitor.monitoring_active}')
"

# Restart monitoring
python main.py --mode chat --enable-monitoring
```

#### **If Dashboard Not Updating**
```bash
# Check data source connection
# In Grafana: Configuration â†’ Data Sources
# Verify Prometheus/JSON data source is working

# Check data flow
python -c "
from monitoring.chatbot_monitor import ChatbotMonitor
monitor = ChatbotMonitor()
data = monitor.get_monitoring_data()
print(f'Data points: {len(data[\"response_metrics\"])}')
"
```

## ğŸ“ˆ System Components

### 1. Patent Filtering (`filtering/filter_g06_patents_optimized.py`)
- **Purpose**: Filters patents with G06 IPC labels and optimizes document size
- **Input**: Raw patent JSON files
- **Output**: Optimized G06 patents with reduced file size (90-99% reduction)
- **Features**:
  - Keeps only essential fields
  - Truncates long text fields
  - Preserves patent metadata

### 2. LightRAG Integration (`lightrag_integration/integrate_lightrag_g06_patents_sequential.py`)
- **Purpose**: Uploads patents to LightRAG one at a time
- **Features**:
  - Sequential processing to avoid server overload
  - Retry mechanism for failed uploads
  - Progress tracking and status monitoring
  - Graceful error handling

### 3. Interactive Chatbot (`chatbot/patent_chatbot.py`)
- **Purpose**: Web-based interface for querying patents
- **Features**:
  - Real-time streaming responses
  - System status monitoring
  - Example queries
  - Clean, modern UI
- **Access**: http://localhost:7860

## ğŸ”§ Configuration Details

### Neo4j Configuration
- **URI**: `bolt://localhost:7687`
- **Username**: `neo4j`
- **Password**: `password`
- **Database**: `lightrag_patents`

### Vector Store Configuration
- **Storage**: NanoVectorDB (JSON files)
- **Location**: `lightrag_storage/`
- **Embedding Model**: bge-m3:latest
- **Dimension**: 1024

### LLM Configuration
- **Model**: qwen2.5:14b-instruct
- **Provider**: Ollama
- **Host**: http://localhost:11434
- **Max Tokens**: 32,768

### RAG Configuration
- **Top-k Retrieval**: 60 similar documents
- **Cosine Threshold**: 0.2
- **Max Graph Nodes**: 10,000
- **History Turns**: 3

## ğŸ“ˆ Performance

### System Requirements
- **RAM**: 16GB minimum, 32GB recommended
- **Storage**: 50GB+ for model and data
- **GPU**: NVIDIA GPU with 8GB+ VRAM (recommended)

### Performance Metrics
- **Document Processing**: ~1-2 seconds per document
- **Vector Search**: <100ms for similarity queries
- **Chatbot Response**: 2-10 seconds depending on query complexity
- **Memory Usage**: ~8-12GB during processing

## ğŸš¨ Troubleshooting

### Common Issues

#### 1. LightRAG Server Won't Start
```bash
# Check if port is in use
lsof -i :9621

# Check Ollama is running
curl http://localhost:11434/api/tags

# Check Neo4j is running
cypher-shell -u neo4j -p password "RETURN 1"
```

#### 2. Document Upload Fails
```bash
# Check LightRAG server health
curl http://localhost:9621/health

# Check document format
python -c "import json; json.load(open('hupd_processed/sample.json'))"
```

#### 3. Chatbot No Response
```bash
# Check LightRAG API
curl -X POST http://localhost:9621/api/chat \
  -H "Content-Type: application/json" \
  -d '{"model": "qwen2.5:14b-instruct", "messages": [{"role": "user", "content": "test"}]}'
```

#### 4. Neo4j Connection Issues
```bash
# Restart Neo4j
brew services restart neo4j

# Check Neo4j logs
tail -f /usr/local/var/log/neo4j/neo4j.log
```

### Best Practices

1. **Always use `.env` file** for configuration
2. **Backup `lightrag_storage/`** directory regularly
3. **Monitor Neo4j** for graph data
4. **Test persistence** after major updates
5. **Keep Neo4j running** when LightRAG is active
6. **Use sequential processing** for large document sets
7. **Monitor memory usage** during processing

## ğŸ“ Current Status

âœ… **File-based storage is working** (data in `lightrag_storage/`)
âœ… **Configuration is correct** (`.env` file created)
âœ… **Pipeline is functional** (all components working)
âœ… **Chatbot is operational** (web interface available)
âš ï¸ **Neo4j storage needs verification** (currently empty)

Your patent analysis pipeline is ready for production use with persistent storage and comprehensive documentation! 

## ğŸ“Š Grafana + PostgreSQL Monitoring System

### Overview
The patent analysis pipeline includes a comprehensive monitoring system using **Grafana** for visualization and **PostgreSQL** for data storage. This provides real-time insights into system performance, chatbot interactions, and component health.

### ğŸ—ï¸ Architecture

```
Chatbot â†’ PostgreSQL â†’ Grafana â†’ Dashboard
   â†“         â†“           â†“         â†“
Response  Store Data  Query Data  Visualize
Metrics   Real-time   Real-time   Real-time
```

### ğŸ“‹ Components

#### 1. **PostgreSQL Database** (`patent_monitoring`)
- **Host**: `localhost:5432`
- **Database**: `patent_monitoring`
- **Tables**:
  - `chat_metrics` - Chatbot interactions
  - `performance_metrics` - Component performance
  - `system_metrics` - System health data

#### 2. **Grafana Dashboard**
- **URL**: `http://localhost:3000`
- **Dashboard**: `simple_postgres_dashboard.json`
- **Data Source**: PostgreSQL
- **Refresh Rate**: 5 seconds

#### 3. **Monitoring Modules**
- `monitoring/postgres_monitor.py` - Core monitoring system
- `monitoring/simple_postgres_dashboard.json` - Dashboard configuration
- `monitoring/test_postgres_monitoring.py` - Testing utilities

### ğŸš€ Setup Instructions

#### 1. **Install PostgreSQL**
```bash
# Install PostgreSQL (if not already installed)
brew install postgresql@14

# Start PostgreSQL service
brew services start postgresql@14

# Create monitoring database
createdb patent_monitoring
```

#### 2. **Install Grafana**
```bash
# Install Grafana
brew install grafana

# Start Grafana service
brew services start grafana

# Access Grafana
open http://localhost:3000
# Default credentials: admin/admin
```

#### 3. **Configure PostgreSQL Data Source**
1. **Open Grafana**: `http://localhost:3000`
2. **Go to**: Configuration â†’ Data Sources
3. **Add PostgreSQL data source**:
   ```
   Host URL: localhost:5432
   Database: patent_monitoring
   User: aniket.rastogi
   Password: (leave blank)
   SSL Mode: disable
   ```
4. **Test connection** and save

#### 4. **Import Dashboard**
1. **Go to**: Dashboards â†’ Import
2. **Upload**: `monitoring/simple_postgres_dashboard.json`
3. **Select**: Your PostgreSQL data source
4. **Import** the dashboard

### ğŸ“ˆ Dashboard Panels

#### **Response Performance**
- **Response Time Over Time**: Line chart showing response times
- **Total Queries**: Count of all chatbot interactions
- **Average Response Time**: Average response time in milliseconds

#### **Component Performance**
- **Performance by Component**: Table showing LightRAG, Neo4j, Ollama, and backup operations
- **LightRAG Operations**: Count of LightRAG operations
- **Neo4j Operations**: Count of Neo4j operations
- **Ollama LLM Operations**: Count of LLM operations
- **Backup Operations**: Count of backup operations

#### **System Health**
- **System Metrics**: CPU and memory usage over time
- **Guardrail Scores**: Profanity, topic relevance, and politeness scores

#### **Recent Activity**
- **Recent Queries**: Table of latest chatbot interactions

### ğŸ”§ Monitoring Integration

#### **Automatic Data Collection**
The monitoring system automatically records:
- **Chatbot interactions** (queries, responses, timing)
- **Component performance** (LightRAG, Neo4j, Ollama, backup)
- **System metrics** (CPU, memory usage)
- **Guardrail scores** (content safety metrics)

#### **Manual Recording**
```python
from monitoring.postgres_monitor import postgres_monitor

# Record LightRAG operation
postgres_monitor.record_lightrag_metric(
    operation="document_retrieval",
    duration_ms=1200,
    success=True,
    documents_retrieved=5
)

# Record Neo4j operation
postgres_monitor.record_neo4j_metric(
    operation="entity_query",
    duration_ms=800,
    success=True,
    nodes_retrieved=12
)

# Record Ollama LLM operation
postgres_monitor.record_ollama_metric(
    operation="text_generation",
    duration_ms=3500,
    success=True,
    tokens_generated=150,
    model_used="qwen2.5:14b-instruct"
)

# Record backup operation
postgres_monitor.record_backup_metric(
    operation="auto_backup",
    duration_ms=5000,
    success=True,
    files_backed_up=20,
    backup_size_mb=120.5
)

# Record server health
postgres_monitor.record_server_health(
    server_name="lightrag",
    is_online=True,
    response_time_ms=120
)
```

### ğŸ“Š Key Metrics

#### **Response Performance**
- **Average Response Time**: Target < 5 seconds
- **Success Rate**: Target > 95%
- **Total Queries**: Track usage patterns

#### **Component Health**
- **LightRAG**: Document retrieval performance
- **Neo4j**: Graph query performance
- **Ollama**: LLM generation performance
- **Backup**: Data backup performance

#### **System Health**
- **CPU Usage**: Target < 70%
- **Memory Usage**: Target < 80%
- **Server Status**: Online/offline status

#### **Content Quality**
- **Profanity Score**: Target > 0.9 (clean responses)
- **Topic Relevance**: Target > 0.8 (relevant responses)
- **Politeness Score**: Target > 0.8 (professional tone)

### ğŸ” Testing Monitoring

#### **Test PostgreSQL Connection**
```bash
# Test database connection
python monitoring/test_postgres_monitoring.py

# Verify monitoring flow
python monitoring/verify_monitoring_flow.py
```

#### **Generate Test Data**
```bash
# Generate sample monitoring data
python -c "
from chatbot.patent_chatbot import PatentChatbot
chatbot = PatentChatbot(enable_monitoring=True)
response = chatbot.get_response('What is machine learning?')
print('âœ… Test data generated')
"
```

### ğŸš¨ Troubleshooting

#### **PostgreSQL Issues**
```bash
# Check PostgreSQL status
brew services list | grep postgresql

# Restart PostgreSQL
brew services restart postgresql@14

# Test connection
psql patent_monitoring -c "SELECT COUNT(*) FROM chat_metrics;"
```

#### **Grafana Issues**
```bash
# Check Grafana status
brew services list | grep grafana

# Restart Grafana
brew services restart grafana

# Check logs
tail -f /usr/local/var/log/grafana/grafana.log
```

#### **Dashboard Not Showing Data**
1. **Check time range** in Grafana (set to "Last 1 hour")
2. **Verify data source** connection
3. **Test queries** manually in Grafana
4. **Generate test data** using the chatbot

#### **Common Error Messages**
- **"Invalid URL"**: Check PostgreSQL connection settings
- **"No data"**: Verify time range and data source
- **"Connection failed"**: Restart PostgreSQL service

### ğŸ“ˆ Performance Baselines

#### **Expected Metrics**
- **Response Time**: 2-10 seconds (depending on query complexity)
- **Success Rate**: > 95%
- **System Uptime**: > 99%
- **Memory Usage**: < 80%
- **CPU Usage**: < 70%

#### **Alert Thresholds**
- **Response Time**: > 15 seconds
- **Success Rate**: < 90%
- **Memory Usage**: > 85%
- **CPU Usage**: > 80%

### ğŸ”„ Data Retention

#### **Automatic Cleanup**
- **Chat metrics**: 30 days retention
- **Performance metrics**: 30 days retention
- **System metrics**: 30 days retention

#### **Manual Cleanup**
```python
from monitoring.postgres_monitor import postgres_monitor

# Clean up old data (older than 30 days)
postgres_monitor.cleanup_old_data(days=30)
```

### ğŸ“‹ Monitoring Commands

#### **Quick Status Check**
```bash
# Check monitoring status
python -c "
from monitoring.postgres_monitor import postgres_monitor
summary = postgres_monitor.get_metrics_summary()
print(f'Total queries: {summary[\"chat_metrics\"][\"total_queries\"]}')
print(f'Avg response time: {summary[\"chat_metrics\"][\"avg_response_time_ms\"]}ms')
"
```

#### **Server Health Check**
```bash
# Check server metrics
python -c "
from monitoring.postgres_monitor import postgres_monitor
summary = postgres_monitor.get_server_metrics_summary()
print('Server Performance:', summary['performance'])
print('Server Health:', summary['health'])
"
```

### ğŸ¯ Best Practices

1. **Regular Monitoring**: Check dashboard daily
2. **Alert Setup**: Configure Grafana alerts for critical metrics
3. **Data Backup**: Regularly backup PostgreSQL data
4. **Performance Tuning**: Monitor and optimize based on metrics
5. **Capacity Planning**: Use metrics for resource planning

The monitoring system provides comprehensive visibility into your patent analysis pipeline, enabling proactive management and optimization of system performance. 

## ğŸ¯ Enhanced Chatbot Usage Examples

### **New Invention Analysis** ğŸ†•
```
User: 2
Bot: ğŸ“ Question 1: What is the title of your invention?

User: Artificial Intelligence System for Autonomous Vehicle Navigation
Bot: ğŸ“ Question 2: Can you provide an abstract of your invention?
(2-3 sentences describing what it does)

User: This system uses machine learning algorithms to process sensor data and make real-time navigation decisions for autonomous vehicles.
Bot: ğŸ“ Question 3: Do you have a detailed description available?

Please select:
- Type 'y' for Yes (I have a detailed description)
- Type 'n' for No (I don't have a detailed description)

User: y
Bot: ğŸ“ Please provide your detailed description:

User: The system includes computer vision modules, sensor fusion algorithms, and decision-making neural networks...
Bot: ğŸ“ Question 4: Select the technology field(s) that best match your invention:

1. Machine Learning & AI
2. Computer Vision & Image Processing
3. Neural Networks & Deep Learning
4. Pattern Recognition & Classification
5. Data Mining & Analytics
6. Bioinformatics & Computational Biology
7. Natural Language Processing
8. Robotics & Automation
9. Signal Processing & Audio
10. Others (search all patents)

You can select multiple fields by entering numbers separated by commas (e.g., 1,3,5)
Or type 'all' to search across all fields:

User: 1,2,3
Bot: ğŸ” Performing RAG-based prior art search...
ğŸ” Patent Analysis Complete

Your Invention:
- Title: Artificial Intelligence System for Autonomous Vehicle Navigation
- Technology Fields: Machine Learning & AI, Computer Vision & Image Processing, Neural Networks & Deep Learning

RAG-Based Prior Art Analysis:
[Comprehensive analysis with similar patents and prior art]

Local Analysis Summary:
[Technical analysis and recommendations]
```

### **Menu Validation** ğŸ†•
```
User: 4
Bot: Option not correctly selected, please select a valid option

ğŸ¤– What type of patent analysis do you need?

1. ğŸ“š Analyze existing patent (from database)
2. ğŸ†• Evaluate new invention idea
3. ğŸ” Search patents by technology/topic

Please choose (1-3):
```

### **Field Selection with "Others"** ğŸ†•
```
User: 10
Bot: ğŸ” Performing RAG-based prior art search...
[Analysis searches across all patent nodes in the database]
```

### **Enhanced Gradio Interface** ğŸ†•
- **Send Button**: Click to submit messages
- **Field Selection Panel**: Separate section below chat
- **Monitoring Panel**: Real-time system status
- **Validation Scores**: Optional display of guardrail scores

### **RAG-Powered Analysis** ğŸ†•
All patent analysis now includes:
- **Prior Art Search**: LightRAG finds similar patents
- **Field-Specific Queries**: Searches within selected technology areas
- **Comprehensive Results**: Combines RAG context with local analysis
- **Fallback Systems**: SQLite and Neo4j when LightRAG unavailable

## ğŸš€ Quick Start with Enhanced Features

### **Launch Web Interface**
```bash
# Launch with enhanced features
python main.py --mode chat --web-interface

# Or launch directly
cd chatbot && python patent_chatbot.py
```

### **Test Enhanced Features**
1. **Menu Validation**: Try entering invalid options (4, 5, etc.)
2. **Length Validation**: Enter short titles/abstracts
3. **Field Selection**: Test multi-select and "Others" option
4. **RAG Integration**: All patent analysis now uses RAG

### **Key Improvements Summary**
- âœ… **Input Validation**: User-friendly error messages
- âœ… **Length Requirements**: Title (10+ chars), Abstract (50+ chars)
- âœ… **Field Categories**: 10 G06N/G06V technology categories
- âœ… **Enhanced RAG**: All analysis uses LightRAG for prior art
- âœ… **Improved UI**: Send button, better organization
- âœ… **Smart Validation**: No gaming of character counts 