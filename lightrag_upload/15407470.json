{
  "patent_number": "None",
  "application_number": "15407470",
  "date_published": "20170921",
  "date_produced": "20170906",
  "filing_date": "20170117",
  "main_ipcr_label": "G06N308",
  "abstract": "A method includes training a neural network having parameters on training data, in which the neural network receives an input state and processes the input state to generate a respective score for each decision in a set of decisions. The method includes receiving training data including training text sequences and, for each training text sequence, a corresponding gold decision sequence. The method includes training the neural network on the training data to determine trained values of parameters of the neural network. Training the neural network includes for each training text sequence: maintaining a beam of candidate decision sequences for the training text sequence, updating each candidate decision sequence by adding one decision at a time, determining that a gold candidate decision sequence matching a prefix of the gold decision sequence has dropped out of the beam, and in response, performing an iteration of gradient descent to optimize an objective function.",
  "publication_number": "US20170270407A1-20170921",
  "summary": "<SOH> SUMMARY <EOH>This specification describes a system implemented as computer programs on one or more computers in one or more locations that processes a text sequence to generate a decision sequence using a globally normalized neural network. In general, one innovative aspect of the subject matter described in this specification can be embodied in methods of training a neural network having parameters on training data, in which the neural network is configured to receive an input state and process the input state to generate a respective score for each decision in a set of decisions. The methods include the actions of receiving first training data, the first training data comprising a plurality of training text sequences and, for each training text sequence, a corresponding gold decision sequence. The methods include the actions of training the neural network on the first training data to determine trained values of the parameters of the neural network from first values of the parameters of the neural network. Training the neural network includes for each training text sequence in the first training data: maintaining a beam of a predetermined number of candidate predicted decision sequences for the training text sequence, updating each candidate predicted decision sequence in the beam by adding one decision at a time to each candidate predicted decision sequence using scores generated by the neural network in accordance with current values of the parameters of the neural network, determining, after each time that a decision has been added to each of the candidate predicted decision sequences, that a gold candidate predicted decision sequence matching a prefix of the gold decision sequence corresponding to the training text sequence has dropped out of the beam, and in response to determining that the gold candidate predicted decision sequence has dropped out of the beam, performing an iteration of gradient descent to optimize an objective function that depends on...",
  "ipcr_labels": [
    "G06N308",
    "G06N304"
  ],
  "inventor_list": [
    {
      "inventor_name_last": "Alberti",
      "inventor_name_first": "Christopher",
      "inventor_city": "New York",
      "inventor_state": "NY",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Severyn",
      "inventor_name_first": "Aliaksei",
      "inventor_city": "Zurich",
      "inventor_state": "",
      "inventor_country": "CH"
    },
    {
      "inventor_name_last": "Andor",
      "inventor_name_first": "Daniel",
      "inventor_city": "New York",
      "inventor_state": "NY",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Petrov",
      "inventor_name_first": "Slav",
      "inventor_city": "New York",
      "inventor_state": "NY",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Ganchev",
      "inventor_name_first": "Kuzman Ganchev",
      "inventor_city": "Forest Hills",
      "inventor_state": "NY",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Weiss",
      "inventor_name_first": "David Joseph",
      "inventor_city": "Philadelphia",
      "inventor_state": "PA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Collins",
      "inventor_name_first": "Michael John",
      "inventor_city": "New York",
      "inventor_state": "NY",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Presta",
      "inventor_name_first": "Alessandro",
      "inventor_city": "San Francisco",
      "inventor_state": "CA",
      "inventor_country": "US"
    }
  ],
  "title": "GLOBALLY NORMALIZED NEURAL NETWORKS",
  "decision": "PENDING",
  "_processing_info": {
    "original_size": 71030,
    "optimized_size": 4573,
    "reduction_percent": 93.56
  }
}