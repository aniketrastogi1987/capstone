{
  "patent_number": "None",
  "application_number": "15432842",
  "date_published": "20180816",
  "date_produced": "20180801",
  "filing_date": "20170214",
  "main_ipcr_label": "G06N304",
  "abstract": "Methods, systems, and computer storage media for implementing neural networks in fixed point arithmetic computing systems. In one aspect, a method includes the actions of receiving a request to process a neural network using a processing system that performs neural network computations using fixed point arithmetic; for each node of each layer of the neural network, determining a respective scaling value for the node from the respective set of floating point weight values for the node; and converting each floating point weight value of the node into a corresponding fixed point weight value using the respective scaling value for the node to generate a set of fixed point weight values for the node; and providing the sets of fixed point floating point weight values for the nodes to the processing system for use in processing inputs using the neural network.",
  "publication_number": "US20180232626A1-20180816",
  "summary": "<SOH> SUMMARY <EOH>This specification describes how a system can implement a neural network in a processing system that performs neural network computation using fixed point arithmetic. To do so, the system converts floating point weight values for each node of the neural network to corresponding fixed point weight values using scaling values generated from the floating point weight values of the node. The system also converts fixed point output value of each node of the last neural network layer to a corresponding floating point weight value using the scaling value of the respective node. In general, one innovative aspect of the subject matter described in this specification can be embodied in methods that include the actions of receiving a request to process a neural network using a processing system that performs neural network computations using fixed point arithmetic, the neural network comprising a plurality of layers, each layer having a plurality of nodes, and each node of each layer having a respective set of floating point weight values; for each node of each layer: determining a respective scaling value for the node from the respective set of floating point weight values for the node; and converting each floating point weight value of the node into a corresponding fixed point weight value using the respective scaling value for the node to generate a set of fixed point weight values for the node; and providing the sets of fixed point floating point weight values for the nodes to the processing system for use in processing inputs using the neural network. The foregoing and other embodiments can each optionally include one or more of the following features, alone or in combination. In particular, one embodiment includes all the following features in combination. The method further comprises receiving a set of fixed point output values generated by the processing system for a last layer of the plurality of layers, each fixed point output value corresponding t...",
  "ipcr_labels": [
    "G06N304",
    "G06F501",
    "G06N308"
  ],
  "inventor_list": [
    {
      "inventor_name_last": "Gulland",
      "inventor_name_first": "William John",
      "inventor_city": "Novato",
      "inventor_state": "CA",
      "inventor_country": "US"
    }
  ],
  "title": "IMPLEMENTING NEURAL NETWORKS IN FIXED POINT ARITHMETIC COMPUTING SYSTEMS",
  "decision": "PENDING",
  "_processing_info": {
    "original_size": 49332,
    "optimized_size": 3452,
    "reduction_percent": 93.0
  }
}