{
  "decision": "PENDING",
  "application_number": "15086561",
  "date_published": "20171005",
  "date_produced": "20170920",
  "title": "CONTROL SYSTEM USING AESTHETICALLY GUIDED GESTURE RECOGNITION",
  "filing_date": "20160331",
  "inventor_list": [
    {
      "inventor_name_last": "ROBERTSON",
      "inventor_name_first": "JAMES R.",
      "inventor_city": "LOS ANGELES",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "SCANLON",
      "inventor_name_first": "RAYMOND J.",
      "inventor_city": "BURBANK",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "HONECK",
      "inventor_name_first": "MICHAEL R.",
      "inventor_city": "GLENDALE",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "JAY",
      "inventor_name_first": "ANGELA",
      "inventor_city": "GLENDALE",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "ROUSE",
      "inventor_name_first": "CORY J.",
      "inventor_city": "GLENDALE",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "IRMLER",
      "inventor_name_first": "HOLGER",
      "inventor_city": "LOS ANGELES",
      "inventor_state": "CA",
      "inventor_country": "US"
    }
  ],
  "ipcr_labels": [
    "G06F301",
    "G06F30482",
    "G06F30484"
  ],
  "main_ipcr_label": "G06F301",
  "summary": "<SOH> SUMMARY <EOH>The following description provides a control assembly or system with an enhanced trigger definition to facilitate real-time, interactive, and triggering or control to select and initiate audio, animation, and/or special effects such as for use with walk-around costumes or costumed characters to operate onboard (or “on-costume”) components. The description also provides a new method or algorithm (and system) for creating the trigger definitions, which are each associated with a particular gesture (e.g., a set of specific movements or motions) performed by an actor or performer who may be wearing a walk-around costume. The inventors recognized that a technical need existed to devise improved hardware and/or software to control and playback asynchronous audio (e.g., rather than a canned playback of an entire scripted show) and/or to provide animation cues. The following description uses a control assembly or system of a walk-around costume as a useful example of its implementation, but it will be readily understood that the control system/assembly and associated ideas described herein are not limited to use with a costumed performer and may be used to facilitate gesture-based control by any number of “actors” or “performers” that use gestures to trigger audio outputs or other events (e.g., special effects, robotic movements, and the like). Similarly, the description provides the example of gestures being provided by a performer wearing a glove, but it should be understood that this is just one example of a “gesture” as being one performed with hand movements. However, the invention is not limited to use with a glove form factor as a gesture may be performed in a wide variety of ways and may range, for example, from a single push button up to full-body motion tracking system to provide user or performer input regarding a gesture. The control assembly or system (and associated method) is not limited to a single input source (e.g., a single glove) or to...",
  "patent_number": "None",
  "abstract": "A method for facilitating and enhancing computer-based authoring of gesture definitions that are useful in controlling a walk-around character and other systems using gesture controls. The method includes, during performance of a gesture by a performer, collecting sets of raw sensor data each corresponding to differing parameters of the performance of the gesture. The method includes displaying a graphical user interface with a graphical plot of each of the sets of raw sensor data. The method includes receiving user input identifying which of the parameters to include in a gesture definition. The method includes, for the graphical plots associated with the chosen parameters receiving user input defining a starting position, an ending position, a maximum value, and a minimum value. The gesture may involve movement of a performer's arms, legs, hands, head, eyes, and so on in a particular manner.",
  "publication_number": "US20170285757A1-20171005",
  "_processing_info": {
    "original_size": 95618,
    "optimized_size": 4267,
    "reduction_percent": 95.54
  }
}