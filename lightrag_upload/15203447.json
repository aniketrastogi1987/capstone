{
  "date_produced": "20171227",
  "publication_number": "US20180012118A1-20180111",
  "main_ipcr_label": "G06N300",
  "decision": "PENDING",
  "application_number": "15203447",
  "inventor_list": [
    {
      "inventor_name_last": "Catten",
      "inventor_name_first": "Jonathan Corey",
      "inventor_city": "Holladay",
      "inventor_state": "UT",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Neil",
      "inventor_name_first": "Oliver",
      "inventor_city": "Sandy",
      "inventor_state": "UT",
      "inventor_country": "US"
    }
  ],
  "abstract": "Embodiments described herein are directed to providing contextually relevant cues to users and to providing cues based on predicted conditions. In one scenario, a computer system identifies a task that is to be performed by a user. The computer system accesses data structures to identify current conditions related to the identified task. The computer system then generates, based on the identified current conditions related to the task, contextually relevant cues for the task. The contextually relevant cues provide suggestive information associated with the task. The computer system further provides the generated cue to the user. In other scenarios, the computer system identifies anticipated conditions related to the task using accessed historical information, and generates contextually relevant cues based on the identified anticipated conditions.",
  "filing_date": "20160706",
  "patent_number": "None",
  "summary": "<SOH> BRIEF SUMMARY <EOH>Embodiments described herein are directed to providing contextually relevant cues to a user and to providing cues based on predicted conditions. In one embodiment, a computer system identifies a task that is to be performed by a user. The computer system accesses data structures to identify current conditions related to the identified task. The computer system then generates, based on the identified current conditions related to the task, contextually relevant cues for the task. The contextually relevant cues provide suggestive information associated with the task. The computer system further provides the generated cue to the user. In another embodiment, a computer system provides cues based on predicted conditions. The computer system identifies a user and accesses historical data related to a task that is to be performed by the identified user. The computer system also identifies anticipated conditions related to the task using the accessed historical information and/or current conditions (directly or indirectly), and generates, based on the identified anticipated conditions, contextually relevant cues related to the task that provide suggestive information associated with the task. The computer system then provides the generated contextually relevant cue to the user. In another embodiment, a graphical user interface is provided by a computer system. The graphical user interface (GUI) includes the following: an initial screen that allows users to view and evaluate contextual information related to a task, a first cue card that has information related to the task, and a second cue card that includes interactive elements that allow a user to drill down into contextual information displayed in the second cue card to find additional contextual information related to the task. The computer system the computer system tracks inputs provided by the user to determine which cue cards are selected and which contextual information is determined to be ...",
  "date_published": "20180111",
  "title": "PREDICTIVE VISUAL AND VERBAL MENTORING",
  "ipcr_labels": [
    "G06N300",
    "G09B1914",
    "G06N700",
    "G09B2910",
    "G06N308"
  ],
  "_processing_info": {
    "original_size": 77062,
    "optimized_size": 3579,
    "reduction_percent": 95.36
  }
}