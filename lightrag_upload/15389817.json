{
  "date_produced": "20180613",
  "publication_number": "US20180181854A1-20180628",
  "main_ipcr_label": "G06N300",
  "decision": "PENDING",
  "application_number": "15389817",
  "inventor_list": [
    {
      "inventor_name_last": "Koukoumidis",
      "inventor_name_first": "Emmanouil",
      "inventor_city": "Kirkland",
      "inventor_state": "WA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Massey",
      "inventor_name_first": "Daniel",
      "inventor_city": "Redmond",
      "inventor_state": "WA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Abramson",
      "inventor_name_first": "Dustin",
      "inventor_city": "Bellevue",
      "inventor_state": "WA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Brinkman, Jr.",
      "inventor_name_first": "Donald F.",
      "inventor_city": "Seattle",
      "inventor_state": "WA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Schwarz",
      "inventor_name_first": "Scott A.",
      "inventor_city": "Seattle",
      "inventor_state": "WA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Tuterov",
      "inventor_name_first": "Sergei",
      "inventor_city": "Redmond",
      "inventor_state": "WA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Wang",
      "inventor_name_first": "Ying",
      "inventor_city": "Redmond",
      "inventor_state": "WA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Yao",
      "inventor_name_first": "Qi",
      "inventor_city": "Bellevue",
      "inventor_state": "WA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Shirey",
      "inventor_name_first": "Adam E.",
      "inventor_city": "Renton",
      "inventor_state": "WA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Alexandropoulou",
      "inventor_name_first": "Maria",
      "inventor_city": "Kirkland",
      "inventor_state": "WA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Stuckart",
      "inventor_name_first": "Kelli",
      "inventor_city": "Redmond",
      "inventor_state": "WA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Wang",
      "inventor_name_first": "Hudong",
      "inventor_city": "Redmond",
      "inventor_state": "WA",
      "inventor_country": "US"
    }
  ],
  "abstract": "Systems and methods for receiving various input data, processing said input data, and utilizing artificial emotional intelligence to analyze said input data to return calculated response stimuli are provided. Various electronic devices may be utilized to acquire input data related to a specific user, a group of users, or environments. This input data, which may comprise tone of voice, facial expressions, social media profiles, and surrounding environmental data, may be compared with past data related to a certain user, group of users, or environment. The systems and methods herein may employ artificial emotional intelligence to evaluate the aggregated data and provide a response stimulus to a user or group of users. The response stimulus may be in the form of uplifting/encouraging music, quotes, pictures, jokes, suggestions, etc. The purpose of providing the response stimuli is to significantly increase the productivity of meetings, conversations, and other interactions across electron...",
  "filing_date": "20161223",
  "patent_number": "None",
  "summary": "<SOH> SUMMARY <EOH>The disclosure generally relates to systems and methods for monitoring user emotional states or communication style and using an artificial-intelligence-based digital conversation assistant (“DCA”) to provide appropriate response stimuli based on the input data received. In one example, the user may request and/or opt-in for detection of user reactions to conversational content for various purposes, such as annotating the content of a business meeting based upon how the participants reacted to at least one portion of the business meeting. The DCA may be a program that receives various types of input data, such as audio data (e.g., tone of voice), visual data (e.g., facial and body expressions), environment data (e.g., specific location), biometric data (e.g., heart rate), participant data (e.g., social media profiles), and solicited feedback from participants. For example, a device (e.g., a mobile phone, a laptop, a tablet device, vehicle instrumentation, a television, an electronic billboard, and/or other devices) may comprise one or more sensors, such as a camera, a motion sensor (e.g., an accelerometer or gyroscope), a GPS device, a microphone, and/or other sensors that may sense and obtain the input data. The DCA then processes that input data by combining it with previously stored data. The previously stored data may comprise past emotional data on users, how certain users responded to specific types of response stimuli, environment data, public information, and other relevant data. Once the newly received input data is combined with the past data, the DCA determines at least one appropriate response stimulus to provide to the user or group of users. The DCA may provide a private, individualized response stimulus to a single user or a group response stimulus to multiple users. The DCA also stores data and provides a system for aggregating data to generate reports, either automatically or manually. In one aspect, a system is provided. The syst...",
  "date_published": "20180628",
  "title": "EQ-DIGITAL CONVERSATION ASSISTANT",
  "ipcr_labels": [
    "G06N300",
    "G06Q1006"
  ],
  "_processing_info": {
    "original_size": 98993,
    "optimized_size": 5164,
    "reduction_percent": 94.78
  }
}