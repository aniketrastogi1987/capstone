{
  "date_produced": "20170607",
  "publication_number": "US20170177996A1-20170622",
  "main_ipcr_label": "G06N308",
  "decision": "PENDING",
  "application_number": "15339701",
  "inventor_list": [
    {
      "inventor_name_last": "Zhao",
      "inventor_name_first": "Xing",
      "inventor_city": "San Diego",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Hamilton",
      "inventor_name_first": "Peter",
      "inventor_city": "Novato",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Story",
      "inventor_name_first": "Andrew K.",
      "inventor_city": "Petaluma",
      "inventor_state": "CA",
      "inventor_country": "US"
    }
  ],
  "abstract": "As part of neural network sensitivity analyses, base outputs of hidden layer nodes of a neural network model for non-perturbed variables can be reused when perturbing the variables. Such an arrangement greatly reduces complexity of the calculations required to generate outputs of the model. Related apparatus, systems, techniques and articles are also described.",
  "filing_date": "20161031",
  "patent_number": "None",
  "summary": "<SOH> SUMMARY <EOH>In one aspect, a plurality of records can be received (either locally or remotely) that each comprise input variables for a plurality of input layer nodes forming part of a neural network. Thereafter, for each record, the input variables are inputted into corresponding input layer nodes to generate a base output for each of a plurality of first hidden layer nodes forming part of the neural network (which can be cached for subsequent re-use) so that a non-perturbed output of the neural network is generated. Subsequently, each input variable, for each record, is perturbed so that an output for the first hidden layer nodes can be generated by reusing the corresponding generated base outputs and a perturbed output for the neural network can be generated. Such information can be used to initiate sensitivity analyses of the neural network sensitivity by comparing the non-perturbed outputs with the perturbed outputs across the input layer nodes. The base outputs can a i determined using: a i = ∑ j = 1 N   w ij  x j + b i where i is an index of the first hidden layer nodes, j is an index of input variables, x is the input variable, w ij is weight from input node j to hidden node i, and b i is bias for hidden node i. For a perturbed input variable k that is perturbed by Δ, the output for the first hidden layer nodes that reuses the corresponding cached generated base output can use: a i  ( k ) = ∑ j = 1 N   w ij  x j + b i + Δ   x k * w ik = a i + Δ   x k * w ik In an interrelated aspect, base outputs are generated for each of a plurality of hidden nodes of a neural network using non-perturbed input variables. Thereafter, an output of the neural network model is generated using perturbed input variables and by reusing the generated base outputs. The output can be then provided (e.g., displayed, transmitted, stored, loaded, etc.). Common indirect sensitivity analysis methods need to evaluate model scores for all records and all input perturbation...",
  "date_published": "20170622",
  "title": "Reduction of Computation Complexity of Neural Network Sensitivity Analysis",
  "ipcr_labels": [
    "G06N308",
    "G06F1711"
  ],
  "_processing_info": {
    "original_size": 34483,
    "optimized_size": 3307,
    "reduction_percent": 90.41
  }
}