{
  "date_produced": "20180131",
  "publication_number": "US20180046919A1-20180215",
  "main_ipcr_label": "G06N308",
  "decision": "PENDING",
  "application_number": "15390559",
  "inventor_list": [
    {
      "inventor_name_last": "LI",
      "inventor_name_first": "Xin",
      "inventor_city": "Beijing",
      "inventor_state": "",
      "inventor_country": "CN"
    },
    {
      "inventor_name_last": "HAN",
      "inventor_name_first": "Song",
      "inventor_city": "Beijing",
      "inventor_state": "",
      "inventor_country": "CN"
    },
    {
      "inventor_name_last": "SUN",
      "inventor_name_first": "Shijie",
      "inventor_city": "Beijing",
      "inventor_state": "",
      "inventor_country": "CN"
    },
    {
      "inventor_name_last": "SHAN",
      "inventor_name_first": "Yi",
      "inventor_city": "Beijing",
      "inventor_state": "",
      "inventor_country": "CN"
    }
  ],
  "abstract": "The present invention relates to artificial neural networks, for example, deep neural networks. In particular, the present invention relates to a multi-iteration compression method for deep neural networks and the device thereof. More specifically, the present invention relates to how to compress dense neural networks into sparse neural networks without degrading the accuracy of the neural",
  "filing_date": "20161226",
  "patent_number": "None",
  "summary": "<SOH> SUMMARY <EOH>According to one aspect of the invention, a method for compressing a neural network is proposed, wherein the weights between the neurons of said neural network are characterized by a plurality of matrices. The method comprises: sensitivity analysis step, for analyzing the sensitivity of each of said plurality of matrices, and determining an initial compression ratio for each of said plurality of matrices; compression step, for compressing each of said plurality of matrices based on said initial compression ratio, so as to obtain a compressed neural network; and fine-tuning step, for fine-tuning said compressed neural network. According to another aspect of the invention, a device for compressing a neural network is proposed, wherein the weights between the neurons of said neural network are characterized by a plurality of matrices. The device comprises: a sensitivity analysis unit, which is used for analyzing the sensitivity of each of said plurality of matrices, and determining an initial compression ratio for each of said plurality of matrices; a compression unit, which is used for compressing each of said plurality of matrices based on said initial compression ratio, so as to obtain a compressed neural network; and a fine-tuning unit, which is used for fine-tuning said compressed neural network.",
  "date_published": "20180215",
  "title": "MULTI-ITERATION COMPRESSION FOR DEEP NEURAL NETWORKS",
  "ipcr_labels": [
    "G06N308",
    "G06N304"
  ],
  "_processing_info": {
    "original_size": 49758,
    "optimized_size": 2683,
    "reduction_percent": 94.61
  }
}