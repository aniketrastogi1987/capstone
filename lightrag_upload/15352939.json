{
  "date_produced": "20180503",
  "publication_number": "US20180137413A1-20180517",
  "main_ipcr_label": "G06N308",
  "decision": "PENDING",
  "application_number": "15352939",
  "inventor_list": [
    {
      "inventor_name_last": "LI",
      "inventor_name_first": "YAZHAO",
      "inventor_city": "TIANJIN",
      "inventor_state": "",
      "inventor_country": "CN"
    }
  ],
  "abstract": "In accordance with an example embodiment of the present invention, a method comprising: obtaining a plurality of training samples; employing a set of activation functions on a plurality of layers of a deep neural network, wherein the set of activation functions varies with the plurality of layers; and applying the activation functions on the plurality of training samples.",
  "filing_date": "20161116",
  "patent_number": "None",
  "summary": "<SOH> SUMMARY <EOH>Various aspects of examples of the invention are set out in the claims. According to a first aspect of the present invention, a method comprising: obtaining a plurality of training samples; employing a set of activation functions on a plurality of layers of a deep neural network, wherein the set of activation functions varies with the plurality of layers; and applying the activation functions on the plurality of training samples. According to a second aspect of the present invention, A non-transitory computer storage medium encoded with a computer program, the program comprising instructions that when executed by one or more computers cause the one or more computers to perform operations comprising: obtaining a plurality of training samples; employing a set of activation functions on a plurality of layers of a deep neural network, wherein the set of activation functions varies with the plurality of layers; and applying the activation functions on the plurality of training samples. According to a third aspect of the present invention, an apparatus comprising: at least one processor, and at least one memory including computer program code, the at least one memory and computer program code configured to, with the at least one processor, cause the apparatus to at least: obtain a plurality of training samples; employ a set of activation functions on a plurality of layers of a deep neural network, wherein the set of activation functions varies with the plurality of layers; and apply the activation functions on the plurality of training samples",
  "date_published": "20180517",
  "title": "DIVERSE ACTIVATION FUNCTIONS FOR DEEP NEURAL NETWORKS",
  "ipcr_labels": [
    "G06N308"
  ],
  "_processing_info": {
    "original_size": 26531,
    "optimized_size": 2487,
    "reduction_percent": 90.63
  }
}