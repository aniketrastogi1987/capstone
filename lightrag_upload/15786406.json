{
  "patent_number": "None",
  "application_number": "15786406",
  "date_published": "20180426",
  "date_produced": "20180411",
  "filing_date": "20171017",
  "main_ipcr_label": "G06N308",
  "abstract": "A method, computer readable medium, and system are disclosed for neural network pruning. The method includes the steps of receiving first-order gradients of a cost function relative to layer parameters for a trained neural network and computing a pruning criterion for each layer parameter based on the first-order gradient corresponding to the layer parameter, where the pruning criterion indicates an importance of each neuron that is included in the trained neural network and is associated with the layer parameter. The method includes the additional steps of identifying at least one neuron having a lowest importance and removing the at least one neuron from the trained neural network to produce a pruned neural network.",
  "publication_number": "US20180114114A1-20180426",
  "summary": "<SOH> SUMMARY <EOH>A method, computer readable medium, and system are disclosed for neural network pruning. The method includes the steps of receiving first-order gradients of a cost function relative to layer parameters for a trained neural network and computing a pruning criterion for each layer parameter based on the first-order gradient corresponding to the layer parameter, where the pruning criterion indicates an importance of each neuron that is included in the trained neural network and is associated with the layer parameter. The method includes the additional steps of identifying at least one neuron having a lowest importance and removing the at least one neuron from the trained neural network to produce a pruned neural network.",
  "ipcr_labels": [
    "G06N308"
  ],
  "inventor_list": [
    {
      "inventor_name_last": "Molchanov",
      "inventor_name_first": "Pavlo",
      "inventor_city": "San Jose",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Tyree",
      "inventor_name_first": "Stephen Walter",
      "inventor_city": "St. Louis",
      "inventor_state": "MO",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Karras",
      "inventor_name_first": "Tero Tapani",
      "inventor_city": "Helsinki",
      "inventor_state": "",
      "inventor_country": "FI"
    },
    {
      "inventor_name_last": "Aila",
      "inventor_name_first": "Timo Oskari",
      "inventor_city": "Tuusula",
      "inventor_state": "",
      "inventor_country": "FI"
    },
    {
      "inventor_name_last": "Kautz",
      "inventor_name_first": "Jan",
      "inventor_city": "Lexington",
      "inventor_state": "MA",
      "inventor_country": "US"
    }
  ],
  "title": "SYSTEMS AND METHODS FOR PRUNING NEURAL NETWORKS FOR RESOURCE EFFICIENT INFERENCE",
  "decision": "PENDING",
  "_processing_info": {
    "original_size": 69871,
    "optimized_size": 2632,
    "reduction_percent": 96.23
  }
}