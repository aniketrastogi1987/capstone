{
  "patent_number": "None",
  "application_number": "15817165",
  "date_published": "20180524",
  "date_produced": "20180509",
  "filing_date": "20171118",
  "main_ipcr_label": "G06N308",
  "abstract": "The technology disclosed presents a novel spatial attention model that uses current hidden state information of a decoder long short-term memory (LSTM) to guide attention and to extract spatial image features for use in image captioning. The technology disclosed also presents a novel adaptive attention model for image captioning that mixes visual information from a convolutional neural network (CNN) and linguistic information from an LSTM. At each timestep, the adaptive attention model automatically decides how heavily to rely on the image, as opposed to the linguistic model, to emit the next caption word. The technology disclosed further adds a new auxiliary sentinel gate to an LSTM architecture and produces a sentinel LSTM (Sn-LSTM). The sentinel gate produces a visual sentinel at each timestep, which is an additional representation, derived from the LSTM's memory, of long and short term visual and linguistic information.",
  "publication_number": "US20180144248A1-20180524",
  "summary": "<SOH> BRIEF DESCRIPTION OF THE DRAWINGS <EOH>The patent or application file of the U.S. priority application contains at least one drawing executed in color. Copies of this patent or patent application publication with color drawing(s) will be provided by the U.S. Patent and Trademark Office upon request and payment of the necessary fee. The color drawings are incorporated by reference herein. In the drawings, like reference characters generally refer to like parts throughout the different views. Also, the drawings are not necessarily to scale, with an emphasis instead generally being placed upon illustrating the principles of the technology disclosed. In the following description, various implementations of the technology disclosed are described with reference to the following drawings, in which: FIG. 1 illustrates an encoder that processes an image through a convolutional neural network (abbreviated CNN) and produces image features for regions of the image. FIG. 2A shows an attention leading decoder that uses previous hidden state information to guide attention and generate an image caption (prior art). FIG. 2B shows the disclosed attention lagging decoder which uses current hidden state information to guide attention and generate an image caption. FIG. 3A depicts a global image feature generator that generates a global image feature for an image by combining image features produced by the CNN encoder of FIG. 1 . FIG. 3B is a word embedder that vectorizes words in a high-dimensional embedding space. FIG. 3C is an input preparer that prepares and provides input to a decoder. FIG. 4 depicts one implementation of modules of an attender that is part of the spatial attention model disclosed in FIG. 6 . FIG. 5 shows one implementation of modules of an emitter that is used in various aspects of the technology disclosed. Emitter comprises a feed-forward neural network (also referred to herein as multilayer perceptron (MLP)), a vocabulary softmax (also referred to herein a...",
  "ipcr_labels": [
    "G06N308",
    "G06F1724",
    "G06K946",
    "G06K900"
  ],
  "inventor_list": [
    {
      "inventor_name_last": "LU",
      "inventor_name_first": "Jiasen",
      "inventor_city": "Atlanta",
      "inventor_state": "GA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "XIONG",
      "inventor_name_first": "Caiming",
      "inventor_city": "Palo Alto",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "SOCHER",
      "inventor_name_first": "Richard",
      "inventor_city": "Menlo Park",
      "inventor_state": "CA",
      "inventor_country": "US"
    }
  ],
  "title": "SENTINEL LONG SHORT-TERM MEMORY (Sn-LSTM)",
  "decision": "PENDING",
  "_processing_info": {
    "original_size": 148629,
    "optimized_size": 3791,
    "reduction_percent": 97.45
  }
}