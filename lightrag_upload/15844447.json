{
  "patent_number": "None",
  "application_number": "15844447",
  "date_published": "20180621",
  "date_produced": "20180608",
  "filing_date": "20171215",
  "main_ipcr_label": "G06N308",
  "abstract": "A machine learning (ML) task system trains a neural network model that learns a compressed representation of acquired data and performs a ML task using the compressed representation. The neural network model is trained to generate a compressed representation that balances the objectives of achieving a target codelength and achieving a high accuracy of the output of the performed ML task. During deployment, an encoder portion and a task portion of the neural network model are separately deployed. A first system acquires data, applies the encoder portion to generate a compressed representation, performs an encoding process to generate compressed codes, and transmits the compressed codes. A second system regenerates the compressed representation from the compressed codes and applies the task model to determine the output of a ML task.",
  "publication_number": "US20180174047A1-20180621",
  "summary": "<SOH> SUMMARY <EOH>A machine learning (ML) task system trains a neural network model to discover structures and patterns of acquired data that are encoded as a compressed codes of the acquired data. The compressed codes includes specific information of the acquired data such that the compressed codes can be decoded and used to determine an output of a machine learning task. In various embodiments, the ML task system does not seek to generate a compressed representation of the acquired data that can be reconstructed as the acquired data, but rather seeks to identify and encode only the information of the acquired data that is needed to perform the ML task. In other words, the ML task system discards information about the acquired data that is less useful for performing the ML task. In some embodiments, the compressed representation of the acquired data generated by the ML task system cannot be decoded or otherwise used to reconstruct the acquired data. Generally, the ML task system trains neural network models that are specific for a particular type of ML task. Therefore, each neural network model learns an efficient representation of acquired data for the particular ML task. The neural network model includes two portions, hereafter referred to as an encoder portion (e.g., encoder model) and a task portion (e.g., task model). In some embodiments, the neural network model includes more than one encoder portion in addition to a task portion. The encoder and task models are jointly trained so that the encoder model learns an efficient representation of the acquired data that can be accurately interpreted by the task model to determine an output of a ML task. In various embodiments, the encoder and task models are trained to minimize a loss function. During training, the ML task system trains the neural network model using training examples that each includes acquired data and a ML task output label. The ML task system trains the encoder model to generate the compressed ...",
  "ipcr_labels": [
    "G06N308",
    "G06N304"
  ],
  "inventor_list": [
    {
      "inventor_name_last": "Bourdev",
      "inventor_name_first": "Lubomir",
      "inventor_city": "Mountain View",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Lew",
      "inventor_name_first": "Carissa",
      "inventor_city": "San Jose",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Nair",
      "inventor_name_first": "Sanjay",
      "inventor_city": "Fremont",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Rippel",
      "inventor_name_first": "Oren",
      "inventor_city": "Mountain View",
      "inventor_state": "CA",
      "inventor_country": "US"
    }
  ],
  "title": "DATA COMPRESSION FOR MACHINE LEARNING TASKS",
  "decision": "PENDING",
  "_processing_info": {
    "original_size": 61991,
    "optimized_size": 3828,
    "reduction_percent": 93.82
  }
}