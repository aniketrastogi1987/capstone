{
  "date_produced": "20180620",
  "publication_number": "US20180189666A1-20180705",
  "main_ipcr_label": "G06N700",
  "decision": "PENDING",
  "application_number": "15393773",
  "inventor_list": [
    {
      "inventor_name_last": "Paluri",
      "inventor_name_first": "Balmanohar",
      "inventor_city": "Mountain View",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Johri",
      "inventor_name_first": "Nikhil",
      "inventor_city": "Mountain View",
      "inventor_state": "CA",
      "inventor_country": "US"
    }
  ],
  "abstract": "In one embodiment an image is processed using a deep-learning model to obtain one or more first predictions. Each first prediction is a likelihood that a respective first concept in a set of first concepts is associated with the image. A feature vector is retrieved for the image. The feature vector is output from a processing layer of the deep-learning model for the image. The feature vector for the image is processed using a first linear model, where the first linear model is trained to detect one or more second concepts. One or more second predictions are obtained from the first linear model. Each second prediction is a likelihood that a respective second concept of the one or more second concepts is associated with the image.",
  "filing_date": "20161229",
  "patent_number": "None",
  "summary": "<SOH> SUMMARY OF PARTICULAR EMBODIMENTS <EOH>In particular embodiments, a system may use one or more deep-learning models to generate a plurality of predictions for a plurality of concepts for an image. Each prediction may be a likelihood that a corresponding concept (e.g., red shirt, octopus, politics) is associated with an image. Deep-learning models (e.g., convolutional neural networks) may be trained to determine predictions (i.e., likelihoods) that concepts are associated with an image. Deep-learning models may be trained using a predetermined set of concepts (i.e., using positive and negative samples of images with respect to the concepts). As used herein, a concept associated with an image may include, as an example and not by way of limitation, an identifiable item depicted in whole or in part in an image (e.g., a person, a blue chair, an oak tree, a dog, a logo, a barcode, or a Quick Response code (â€œQR code)), a visual property of an image or a part of an image (e.g., the color green in an image, a sepia-filtered image, a blurry image, lighting conditions associated with the image), metadata associated with the image, a category associated with the image (e.g., politics, marriage, or clean eating), a mood associated with an image (e.g., spooky or happy), an event associated with an image (e.g., a wedding, a Butch Walker concert, Election Day 2016), a location (e.g., Pennsylvania or Franklin & Marshall College), any concept that may represented by a node in a social graph and that may be associated with an image, any other concept identifiable in or associated with an image, or any combination thereof. Concepts may be arranged in any suitable number of taxonomies. It will be understood that as used herein, an image may be any visual scene that may be captured in one or more frames, including, as an example and not by way of limitation, pictures, videos, or any combination thereof. A deep-learning model may be trained to determine predictions for a particular...",
  "date_published": "20180705",
  "title": "Adding Concepts to a Deep-Learning Model in Real Time",
  "ipcr_labels": [
    "G06N700",
    "G06N308"
  ],
  "_processing_info": {
    "original_size": 78310,
    "optimized_size": 3454,
    "reduction_percent": 95.59
  }
}