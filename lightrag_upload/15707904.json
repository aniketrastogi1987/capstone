{
  "patent_number": "None",
  "application_number": "15707904",
  "date_published": "20180322",
  "date_produced": "20180308",
  "filing_date": "20170918",
  "main_ipcr_label": "G06N502",
  "abstract": "The present design is directed to a system for dispatching cognitive computing across multiple workers, comprising a supervisory node configured to dispatch work to a plurality of compute servers forming interconnected knowledge nodes and a relevancy engine provided in at least one knowledge node. The relevancy engine comprises a rule package and a series of processors organized in a tree arrangement, the series of processors configured to perform functions according to the rule package.",
  "publication_number": "US20180082190A1-20180322",
  "summary": "<SOH> SUMMARY OF THE INVENTION <EOH>Thus according to one aspect of the present design, there is provided a system for dispatching cognitive computing across multiple workers, comprising a supervisory node configured to dispatch work to a plurality of compute servers forming interconnected knowledge nodes and a relevancy engine provided in at least one knowledge node. The relevancy engine comprises a rule package and a series of processors organized in a tree arrangement, the series of processors configured to perform functions according to the rule package. According to a further aspect of the present design, there is provided a system for dispatching cognitive computing across multiple workers, comprising a plurality of compute servers forming interconnected knowledge nodes, wherein one of the interconnected supervisory nodes comprises a supervisory node configured to dispatch work to at least one knowledge node. One knowledge node comprises a relevancy engine comprising a series of processors organized in a tree arrangement, the series of processors configured to perform functions according to a rule set. According to a further aspect of the present design, there is provided a system for dispatching cognitive computing across multiple workers, comprising a plurality of compute servers configured to form a supervisory node configured to dispatch work and a plurality of interconnected knowledge nodes, with a relevancy engine provided in at least one interconnected knowledge node. The relevancy engine comprises a series of processors organized in a tree arrangement, the series of processors configured to perform functions according to a rule package. These and other advantages of the present invention will become apparent to those skilled in the art from the following detailed description of the invention and the accompanying drawings.",
  "ipcr_labels": [
    "G06N502",
    "G06N9900"
  ],
  "inventor_list": [
    {
      "inventor_name_last": "Cormier",
      "inventor_name_first": "Michael E.",
      "inventor_city": "Delray Beach",
      "inventor_state": "FL",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Cox",
      "inventor_name_first": "Earl D.",
      "inventor_city": "Delray Beach",
      "inventor_state": "FL",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Thackrey",
      "inventor_name_first": "William E.",
      "inventor_city": "Delray Beach",
      "inventor_state": "FL",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "McGlynn",
      "inventor_name_first": "Joseph",
      "inventor_city": "Delray Beach",
      "inventor_state": "FL",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Gardner",
      "inventor_name_first": "Harry",
      "inventor_city": "Delray Beach",
      "inventor_state": "FL",
      "inventor_country": "US"
    }
  ],
  "title": "SYSTEM FOR DISPATCHING COGNITIVE COMPUTING ACROSS MULTIPLE WORKERS",
  "decision": "PENDING",
  "_processing_info": {
    "original_size": 165559,
    "optimized_size": 3536,
    "reduction_percent": 97.86
  }
}