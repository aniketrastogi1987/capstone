{
  "patent_number": "None",
  "application_number": "15478823",
  "date_published": "20171012",
  "date_produced": "20170927",
  "filing_date": "20170404",
  "main_ipcr_label": "G06N308",
  "abstract": "A computer-implemented method for training a deep neural network to recognize traffic scenes (TSs) from multi-modal sensors and knowledge data is presented. The computer-implemented method includes receiving data from the multi-modal sensors and the knowledge data and extracting feature maps from the multi-modal sensors and the knowledge data by using a traffic participant (TS) extractor to generate a first set of data, using a static objects extractor to generate a second set of data, and using an additional information extractor. The computer-implemented method further includes training the deep neural network, with training data, to recognize the TSs from a viewpoint of a vehicle.",
  "publication_number": "US20170293837A1-20171012",
  "summary": "<SOH> SUMMARY <EOH>A computer-implemented method for training a deep neural network to recognize traffic scenes (TSs) from multi-modal sensors and knowledge data is presented. The method includes receiving data from the multi-modal sensors and the knowledge data and extracting feature maps from the multi-modal sensors and the knowledge data by using a traffic participant (TS) extractor to generate a first set of data, using a static objects extractor to generate a second set of data, and using an additional information extractor. The computer-implemented method further includes training the deep neural network, with training data to recognize the TSs from a viewpoint of a vehicle. A system for training a deep neural network to recognize traffic scenes (TS s) from multi-modal sensors and knowledge data is presented. The system includes a memory and a processor in communication with the memory, wherein the processor is configured to receive data from the multi-modal sensors and the knowledge data and extract feature maps from the multi-modal sensors and the knowledge data by using a traffic participant (TS) extractor to generate a first set of data, using a static objects extractor to generate a second set of data, and using an additional information extractor. The computer-implemented system further includes training the deep neural network, with training data to recognize the TSs from a viewpoint of a vehicle. A non-transitory computer-readable storage medium comprising a computer-readable program for training a deep neural network to recognize traffic scenes (TSs) from multi-modal sensors and knowledge data is presented, wherein the computer-readable program when executed on a computer causes the computer to perform the steps of receiving data from the multi-modal sensors and the knowledge data and extracting feature maps from the multi-modal sensors and the knowledge data by using a traffic participant (TS) extractor to generate a first set of data, using a static...",
  "ipcr_labels": [
    "G06N308",
    "G06N304"
  ],
  "inventor_list": [
    {
      "inventor_name_last": "Cosatto",
      "inventor_name_first": "Eric",
      "inventor_city": "Red Bank",
      "inventor_state": "NJ",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Melvin",
      "inventor_name_first": "Iain",
      "inventor_city": "Hopewell",
      "inventor_state": "NJ",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Graf",
      "inventor_name_first": "Hans Peter",
      "inventor_city": "Lincroft",
      "inventor_state": "NJ",
      "inventor_country": "US"
    }
  ],
  "title": "Multi-Modal Driving Danger Prediction System for Automobiles",
  "decision": "PENDING",
  "_processing_info": {
    "original_size": 41477,
    "optimized_size": 3542,
    "reduction_percent": 91.46
  }
}