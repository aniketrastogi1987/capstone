{
  "patent_number": "None",
  "application_number": "15678864",
  "date_published": "20180301",
  "date_produced": "20180213",
  "filing_date": "20170816",
  "main_ipcr_label": "G06N308",
  "abstract": "A computer-implemented method is provided for neural network training. The method includes improving a cache utilization by one or more processors during multiple training stages of a neural network, by performing a stage-wise mini-batch process on a set of samples used for the multiple training stages. The stage-wise mini-batch process waits for each of the multiple training stages to complete using a system wait primitive to improve the cache utilization.",
  "publication_number": "US20180060731A1-20180301",
  "summary": "<SOH> SUMMARY <EOH>According to an aspect of the present invention, a computer-implemented method is provided for neural network training. The method includes improving a cache utilization by one or more processors during multiple training stages of a neural network, by performing a stage-wise mini-batch process on a set of samples used for the multiple training stages. The stage-wise mini-batch process waits for each of the multiple training stages to complete using a system wait primitive to improve the cache utilization. According to another aspect of the present invention, a computer program product is provided for neural network training. The computer program product includes a non-transitory computer readable storage medium having program instructions embodied therewith. The program instructions are executable by a computer to cause the computer to perform a method. The method includes improving a cache utilization by one or more processors during multiple training stages of a neural network, by performing a stage-wise mini-batch process on a set of samples used for the multiple training stages. The stage-wise mini-batch process waits for each of the multiple training stages to complete using a system wait primitive to improve the cache utilization. According to yet another aspect of the present invention, a system is provided for neural network training. The system includes one or more processors configured to improve a cache utilization thereby during multiple training stages of a neural network, by performing a stage-wise mini-batch process on a set of samples used for the multiple training stages. The stage-wise mini-batch process waits for each of the multiple training stages to complete using a system wait primitive to improve the cache utilization. These and other features and advantages will become apparent from the following detailed description of illustrative embodiments thereof, which is to be read in connection with the accompanying drawings.",
  "ipcr_labels": [
    "G06N308",
    "G06N3063"
  ],
  "inventor_list": [
    {
      "inventor_name_last": "Kadav",
      "inventor_name_first": "Asim",
      "inventor_city": "Jersey City",
      "inventor_state": "NJ",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Lai",
      "inventor_name_first": "Farley",
      "inventor_city": "Princeton",
      "inventor_state": "IA",
      "inventor_country": "US"
    }
  ],
  "title": "STAGE-WISE MINI BATCHING TO IMPROVE CACHE UTILIZATION",
  "decision": "PENDING",
  "_processing_info": {
    "original_size": 31642,
    "optimized_size": 3150,
    "reduction_percent": 90.04
  }
}