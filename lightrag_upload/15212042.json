{
  "date_produced": "20170119",
  "publication_number": "US20170032245A1-20170202",
  "main_ipcr_label": "G06N308",
  "decision": "PENDING",
  "application_number": "15212042",
  "inventor_list": [
    {
      "inventor_name_last": "Osband",
      "inventor_name_first": "Ian David Moffat",
      "inventor_city": "Stanford",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Van Roy",
      "inventor_name_first": "Benjamin",
      "inventor_city": "Stanford",
      "inventor_state": "CA",
      "inventor_country": "US"
    }
  ],
  "abstract": "Systems and methods for providing reinforcement learning for a deep learning network are disclosed. A reinforcement learning process that provides deep exploration is provided by a bootstrap that applied to a sample of observed and artificial data to facilitate deep exploration via a Thompson sampling approach.",
  "filing_date": "20160715",
  "patent_number": "None",
  "summary": "<SOH> SUMMARY <EOH>The above and other problems are solved and an advance in the art is made by systems and methods for providing reinforcement learning in deep learning networks in accordance with some embodiments of the invention. Reinforcement learning with deep exploration is provided in the following manner in accordance with some embodiments of the invention. A deep neural network is maintained. A reinforcement learning process is applied to the deep neural network. The reinforcement learning process is performed in the following manner in accordance with some embodiments. A set of observed data and a set artificial data is received. For each of a number of episodes, the process samples a set of data that is a union of the set of observed data and the set of artificial data to generate set of training data. A state-action value function is then determined for the set of training data using a bootstrap process and an approximator. The approximator estimates a state-action function for a dataset. For each time step in each of the one or more episodes, the process determines a state of the system for a current time step from the set of training data. An action based on the determined state of the system and a policy mapping actions to the state of the system is selected by the process and results for the action including a reward and a transition state that result from the selected action are determined. Result data from the current time step that includes the state, the action, the transition state are stored. The set of the observed data is then updated with the result data from at least one time step of an episode at the conclusion of an episode. In accordance with some embodiments, the reinforcement learning process generates the set of artificial data from the set of observed data. In accordance with many of these embodiments the artificial data is generated by sampling the set of observed data with replacement to generate the set of artificial data. In acco...",
  "date_published": "20170202",
  "title": "Systems and Methods for Providing Reinforcement Learning in a Deep Learning System",
  "ipcr_labels": [
    "G06N308",
    "G06N9900"
  ],
  "_processing_info": {
    "original_size": 76103,
    "optimized_size": 3053,
    "reduction_percent": 95.99
  }
}