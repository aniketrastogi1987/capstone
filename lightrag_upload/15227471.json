{
  "date_produced": "20180124",
  "publication_number": "US20180039884A1-20180208",
  "main_ipcr_label": "G06N308",
  "decision": "PENDING",
  "application_number": "15227471",
  "inventor_list": [
    {
      "inventor_name_last": "DALTON",
      "inventor_name_first": "Barnaby",
      "inventor_city": "Mississauga",
      "inventor_state": "",
      "inventor_country": "CA"
    },
    {
      "inventor_name_last": "COURVILLE",
      "inventor_name_first": "Vanessa",
      "inventor_city": "Etobicoke",
      "inventor_state": "",
      "inventor_country": "CA"
    },
    {
      "inventor_name_last": "SALDANA",
      "inventor_name_first": "Manuel",
      "inventor_city": "Toronto",
      "inventor_state": "",
      "inventor_country": "CA"
    }
  ],
  "abstract": "A system for training a neural network includes a first set of neural network units and a second set of neural networking units. Each neural network unit in the first set is configured to compute parameter update data for one of a plurality of instances of a first portion of the neural network. Each neural network unit in the first set includes a communication interface for communicating its parameter update data for combination with parameter update data from another neural network unit in the first set. Each neural network unit in the second set is configured to compute parameter update data for one of a plurality of instances of a second portion of the neural network. Each neural network unit in the second set includes a communication interface for communicating its parameter update data for combination with parameter update data from another neural network unit in the second set.",
  "filing_date": "20160803",
  "patent_number": "None",
  "summary": "<SOH> SUMMARY <EOH>In an aspect, there is provided a system for training a neural network having a plurality of interconnected layers. The system includes a first set of neural network units and a second set of neural networking units. Each neural network unit in the first set is configured to compute parameter update data for one of a plurality of instances of a first portion of the neural network. Each neural network unit in the first set includes a communication interface for communicating its parameter update data for combination with parameter update data from another neural network unit in the first set. Each neural network unit in the second set is configured to compute parameter update data for one of a plurality of instances of a second portion of the neural network. Each neural network unit in the second set includes a communication interface for communicating its parameter update data for combination with parameter update data from another neural network unit in the second set. In another aspect, there is provided a method for training a neural network with an architecture having a plurality of instances of the neural network. The method includes: for each neural network unit in a first set of neural network units configured to compute parameter update data for one of a plurality of instances of a first portion of the neural network, communicating the parameter update data generated by the neural network unit for combination with parameter update data from another neural network unit in the first set; and for each neural network unit in a second set of neural network units configured to compute parameter update data for one of a plurality of instances of a second portion of the neural network, communicating the parameter update data generated by the neural network unit for combination with parameter update data from another neural network unit in the second set. In another aspect, there is provided a non-transitory, computer-readable medium or media havin...",
  "date_published": "20180208",
  "title": "SYSTEMS, METHODS AND DEVICES FOR NEURAL NETWORK COMMUNICATIONS",
  "ipcr_labels": [
    "G06N308",
    "G06N304"
  ],
  "_processing_info": {
    "original_size": 52622,
    "optimized_size": 3752,
    "reduction_percent": 92.87
  }
}