{
  "date_produced": "20170110",
  "publication_number": "US20170024664A1-20170126",
  "main_ipcr_label": "G06N9900",
  "decision": "PENDING",
  "application_number": "15283079",
  "inventor_list": [
    {
      "inventor_name_last": "Xiong",
      "inventor_name_first": "Tao",
      "inventor_city": "Beijing",
      "inventor_state": "",
      "inventor_country": "CN"
    },
    {
      "inventor_name_last": "Wang",
      "inventor_name_first": "Wei",
      "inventor_city": "Beijing",
      "inventor_state": "",
      "inventor_country": "CN"
    },
    {
      "inventor_name_last": "Zhang",
      "inventor_name_first": "Guoxin",
      "inventor_city": "Beijing",
      "inventor_state": "",
      "inventor_country": "CN"
    },
    {
      "inventor_name_last": "Wang",
      "inventor_name_first": "Zhibing",
      "inventor_city": "Beijing",
      "inventor_state": "",
      "inventor_country": "CN"
    }
  ],
  "abstract": "In one embodiment, the method incorporates a first set of words that belong to a topic in a set of topics that correspond to a set of genomes in a model, the words being incorporated in the model via a first item in the model. Then, the method incorporates a relationship between a second set of words that are associated with topics in the set of topics via a second item in the model. The model is trained with respect to the first item and the second item to determine a probability distribution of terms for the set of topics based on analyzing textual information for a plurality of media programs. The method further scores terms for each of the plurality of media programs based on the trained model to rank topics that correspond to genomes, the genomes describing characteristics for each media program.",
  "filing_date": "20160930",
  "patent_number": "None",
  "summary": "<SOH> SUMMARY <EOH>In one embodiment, the method incorporates a first set of words that belong to a topic in a set of topics that correspond to a set of genomes in a model, the words being incorporated in the model via a first item in the model. Then, the method incorporates a relationship between a second set of words that are associated with topics in the set of topics via a second item in the model. The model is trained with respect to the first item and the second item to determine a probability distribution of terms for the set of topics based on analyzing textual information for a plurality of media programs. The method further scores terms for each of the plurality of media programs based on the trained model to rank topics that correspond to genomes, the genomes describing characteristics for each media program. In one embodiment, a non-transitory computer-readable storage medium contains instructions, that when executed, control a computer system to be configured for: incorporating a first set of words that belong to a topic in a set of topics that correspond to a set of genomes in a model, the words being incorporated in the model via a first item in the model; incorporating a relationship between a second set of words that are associated with topics in the set of topics via a second item in the model; training the model with respect to the first item and the second item to determine a probability distribution of terms for the set of topics based on analyzing textual information for a plurality of media programs; and scoring terms for each of the plurality of media programs based on the trained model to rank topics that correspond to genomes, the genomes describing characteristics for each media program. In one embodiment, an apparatus includes: one or more computer processors; and a non-transitory computer-readable storage medium comprising instructions, that when executed, control the one or more computer processors to be configured for: incorporating a ...",
  "date_published": "20170126",
  "title": "Topic Model Based Media Program Genome Generation For A Video Delivery System",
  "ipcr_labels": [
    "G06N9900",
    "G06N312",
    "G06F1730",
    "G06N700"
  ],
  "_processing_info": {
    "original_size": 59713,
    "optimized_size": 3828,
    "reduction_percent": 93.59
  }
}