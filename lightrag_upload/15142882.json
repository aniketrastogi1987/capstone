{
  "date_produced": "20171018",
  "publication_number": "US20170316321A1-20171102",
  "main_ipcr_label": "G06N504",
  "decision": "PENDING",
  "application_number": "15142882",
  "inventor_list": [
    {
      "inventor_name_last": "Whitney",
      "inventor_name_first": "Jonathan",
      "inventor_city": "Belmont",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Lu",
      "inventor_name_first": "Zhijiang",
      "inventor_city": "Union City",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Rusin",
      "inventor_name_first": "Rafal",
      "inventor_city": "Pleasanton",
      "inventor_state": "CA",
      "inventor_country": "US"
    }
  ],
  "abstract": "In one aspect, a system for pre-fetching performance data in a monitored environment is disclosed. The system can include a processor; a memory; and one or more modules stored in the memory. The one or more modules are executable by the processor to perform operations including: record queries that request for application performance data with latencies longer than a threshold; learn access patterns in the recorded queries with latencies longer than the threshold; pre-fetch and cache the application performance data requested by the recorded queries before the same recorded queries are requested next time; and provide the pre-fetched application performance data from the cache when the same recorded queries are requested next time.",
  "filing_date": "20160429",
  "patent_number": "None",
  "summary": "<SOH> SUMMARY <EOH>Examples of implementations for predictively rolling up and caching application performance data are disclosed. In one aspect, a system for pre-fetching performance data in a monitored environment is disclosed. The system can include a processor; a memory; and one or more modules stored in the memory. The one or more modules are executable by the processor to perform operations including: record queries that request for application performance data with latencies longer than a threshold; learn access patterns in the recorded queries with latencies longer than the threshold; pre-fetch and cache the application performance data requested by the recorded queries before the same recorded queries are requested next time; and provide the pre-fetched application performance data from the cache when the same recorded queries are requested next time. The system can be implemented in various ways to include one or more of the following features. For example, the one or more modules stored in the memory can be executable by the processor to perform operations including: determine newly streamed performance data is relevant to the pre-fetched and cached performance data; and append the pre-fetched and cached data with the newly streamed performance data that are determined to be relevant. The one or more modules stored in the memory can be executable by the processor to pre-fetch and cache the application performance data by performing operations including: identify a type of performance data; identify a roll up process mandated by the recorded queries; and pre-processing the identified type of performance data using the identified roll up process. The roll up process can include raw data in minute interval, average hourly data, average daily data, average weekly data, average monthly data, or average yearly data. The access pattern can include hourly, daily, weekly, monthly, or yearly access. The application performance data can include time needed to comple...",
  "date_published": "20171102",
  "title": "PREDICTIVE ROLLUP AND CACHING FOR APPLICATION PERFORMANCE DATA",
  "ipcr_labels": [
    "G06N504",
    "H04L2908",
    "G06N9900"
  ],
  "_processing_info": {
    "original_size": 70958,
    "optimized_size": 3609,
    "reduction_percent": 94.91
  }
}