{
  "date_produced": "20171108",
  "publication_number": "US20170337463A1-20171123",
  "main_ipcr_label": "G06N304",
  "decision": "PENDING",
  "application_number": "15258691",
  "inventor_list": [
    {
      "inventor_name_last": "DALTON",
      "inventor_name_first": "Barnaby",
      "inventor_city": "Mississauga",
      "inventor_state": "",
      "inventor_country": "CA"
    },
    {
      "inventor_name_last": "SOZUBEK",
      "inventor_name_first": "Serdar",
      "inventor_city": "Toronto",
      "inventor_state": "",
      "inventor_country": "CA"
    },
    {
      "inventor_name_last": "SALDANA",
      "inventor_name_first": "Manuel",
      "inventor_city": "Toronto",
      "inventor_state": "",
      "inventor_country": "CA"
    },
    {
      "inventor_name_last": "COURVILLE",
      "inventor_name_first": "Vanessa",
      "inventor_city": "Etobicoke",
      "inventor_state": "",
      "inventor_country": "CA"
    }
  ],
  "abstract": "The present disclosure is drawn to the reduction of parameters in fully connected layers of neural networks. For a layer whose output is defined by y=Wx, where y is the output vector, x is the input vector, and W is a matrix of connection parameters, vectors uij and ij are defined and submatrices Wi,j are computed as the outer product of uij and ij, so that Wi,j=ijuij, and W is obtained by appending submatrices Wi,j.",
  "filing_date": "20160907",
  "patent_number": "None",
  "summary": "<SOH> SUMMARY <EOH>The present disclosure is drawn to the reduction of parameters in fully connected layers of neural networks. For a layer whose output is defined by y=Wx, where y is the output vector, x is the input vector, and W is a matrix of connection parameters, vectors u ij and ij are defined and submatrices W i,j are computed as the outer product of u ij and ij , so that W i,j = ij u ij , and W is obtained by appending submatrices W i,j . In accordance with a broad aspect, there is provided a method for creating a neural network layer. An n-dimensional input vector x and an m-dimensional output vector y are defined. The output vector y is partitioned into equally sized subvectors y i of length s and partitioning the input vector x into equally sized subvectors x j of length t. A vector u ij of length t and a vector ij of length s are defined for i=(1, . . . , m/s) and j=(1, . . . , n/t). Submatrices W ij are computed as an outer product of the vector u ij and the vector ij so that W ij =u ij T ij , and the output vector y is determined from y=W·x, where W is a matrix composed of all submatrices W ij for i=(1, . . . , m/s) and j=(1, . . . n/t). In some embodiments, determining the output vector y from y=W·x comprises computing y i =Σ j=1 n/t (W ij x j ) and determining the output vector y as y=[y 1 , y 2 , y 3 , ym /s ]. In some embodiments, determining the output vector y from y=W·x comprises appending submatrices W ij to obtain matrix Wand computing y=W·x. In some embodiments, the method further comprises storing the vectors ij and u ij . In some embodiments, the method further comprises retrieving the vectors ij and u ij to compute the matrices W i,h . In some embodiments, the neural network is a feedforward neural network and/or a deep neural network. In some embodiments, the method further comprises learning the vectors u ij and ij during a training phase of the neural network. In accordance with another broad aspect, there is provided a system for crea...",
  "date_published": "20171123",
  "title": "REDUCTION OF PARAMETERS IN FULLY CONNECTED LAYERS OF NEURAL NETWORKS",
  "ipcr_labels": [
    "G06N304",
    "G06N308"
  ],
  "_processing_info": {
    "original_size": 37473,
    "optimized_size": 3451,
    "reduction_percent": 90.79
  }
}