{
  "patent_number": "None",
  "application_number": "15815309",
  "date_published": "20180524",
  "date_produced": "20180509",
  "filing_date": "20171116",
  "main_ipcr_label": "G06N308",
  "abstract": "Approaches for classifying training samples with minimal error in a neural network using a low complexity neural network classifier, are described. In one example, for the neural network, an upper bound on the Vapnik-Chervonenkis (VC) dimension is determined. Thereafter, an empirical error function corresponding to the neural network is determined. A modified error function based on the upper bound on the VC dimension and the empirical error function is generated, and used for training the neural network.",
  "publication_number": "US20180144246A1-20180524",
  "summary": "<SOH> BRIEF DESCRIPTION OF THE DRAWINGS <EOH>The following detailed description references the drawings, wherein: FIG. 1 is a diagram of an example system for classifying training samples with minimal error using a low complexity neural network classifier; FIG. 2 illustrates an exemplary twin neural network, as per an example of the present subject matter; FIG. 3 depicts an example method for classifying training samples with minimal error using a low complexity neural network classifier; FIG. 4 illustrates a graphical plot between the training time and number of training samples for a system for classifying training samples with minimal error, as per an example of the present subject matter; FIG. 5 illustrates depicts variation between testing accuracy and number of training samples for a system for classifying training samples with minimal error, as per an example of the present subject matter; FIG. 6A illustrates a histogram of the weight values for sparse autoencoders based on the LCNN for a system for classifying training samples with minimal error, as per an example of the present subject matter; FIG. 6B illustrates a histogram of the weight values for sparse autoencoders based on the RFNNs for a system for classifying training samples with minimal error, as per an example of the present subject matter; FIG. 7 illustrates a graphical representation of CNN-LCNN experiments for a system for classifying training samples with minimal error, as per an example of the present subject matter; FIG. 8 illustrates a graphical representation of DBN-LCNN Experiments for a system for classifying training samples with minimal error, as per an example of the present subject matter; and FIG. 9 illustrates a graphical representation of Denoising Autoencoder-LCNN Experiments for a system for classifying training samples with minimal error, as per an example of the present subject matter. detailed-description description=\"Detailed Description\" end=\"lead\"?",
  "ipcr_labels": [
    "G06N308"
  ],
  "inventor_list": [
    {
      "inventor_name_last": "Jayadeva",
      "inventor_name_first": "",
      "inventor_city": "New Delhi",
      "inventor_state": "",
      "inventor_country": "IN"
    }
  ],
  "title": "Neural Network Classifier",
  "decision": "PENDING",
  "_processing_info": {
    "original_size": 72248,
    "optimized_size": 2994,
    "reduction_percent": 95.86
  }
}