{
  "date_produced": "20180328",
  "publication_number": "US20180101776A1-20180412",
  "main_ipcr_label": "G06N504",
  "decision": "PENDING",
  "application_number": "15291305",
  "inventor_list": [
    {
      "inventor_name_last": "Osotio",
      "inventor_name_first": "Neal",
      "inventor_city": "Sammamish",
      "inventor_state": "WA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Sanchez",
      "inventor_name_first": "Eva Marina Illescas",
      "inventor_city": "Bellevue",
      "inventor_state": "WA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Park",
      "inventor_name_first": "YoungSun",
      "inventor_city": "Bellevue",
      "inventor_state": "WA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Paine",
      "inventor_name_first": "Llewyn Elise",
      "inventor_city": "Bellevue",
      "inventor_state": "WA",
      "inventor_country": "US"
    }
  ],
  "abstract": "Representative embodiments disclose mechanisms to extract an emotional state from contextual user data and public use data collected from one or more devices and/or services. The contextual and public data are combined into an enriched data set. An emotional model, tailored to the user, extracts an emotional state form the enriched data set based on one or more machine learning techniques. The emotional state is used to identify one or more actions that change operation of one or more devices and/or services in order to achieve a change in emotional state, compatibility between the emotional state and device and/or service interaction with the user, or both. Implicit and/or explicit feedback is collected and used to change prediction of the emotional state and/or selection of the actions.",
  "filing_date": "20161012",
  "patent_number": "None",
  "summary": "<SOH> BRIEF DESCRIPTION OF DRAWINGS <EOH>FIG. 1 illustrates an example architecture of a system to extract an emotional state from various data sources. FIG. 2 illustrates an example learning loop to improve a system's ability to extract an emotional state from collected data. FIG. 3 illustrates an example flow diagram to extract an emotional state from data and to customize operation of a system based on the extracted emotional state. FIG. 4 illustrates an example architecture to identify an emotional state from data and to customize operation of a system based on the extracted emotional state. FIG. 5 illustrates another example architecture to identify an emotional state from data and to customize operation of a system based on the extracted emotional state. FIG. 6 illustrates another example architecture to identify an emotional state from data and to customize operation of a system based on the extracted emotional state. FIG. 7 illustrates a representative machine architecture suitable for implementing the systems and so forth or for executing the methods disclosed herein. detailed-description description=\"Detailed Description\" end=\"lead\"?",
  "date_published": "20180412",
  "title": "Extracting An Emotional State From Device Data",
  "ipcr_labels": [
    "G06N504",
    "G06F1730",
    "G06N9900",
    "G06N300"
  ],
  "_processing_info": {
    "original_size": 87627,
    "optimized_size": 2986,
    "reduction_percent": 96.59
  }
}