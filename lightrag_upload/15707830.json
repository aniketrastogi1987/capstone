{
  "patent_number": "None",
  "application_number": "15707830",
  "date_published": "20180322",
  "date_produced": "20180308",
  "filing_date": "20170918",
  "main_ipcr_label": "G06N502",
  "abstract": "The present design is directed to a series of interconnected compute servers including a supervisory hardware node and a plurality of knowledge hardware nodes, wherein the series of interconnected compute servers are configured to categorize and scale performance of multiple disjoint algorithms across a seemingly infinite actor population, wherein the series of interconnected compute servers are configured to normalize data using a common taxonomy, distribute normalized data relatively evenly across the plurality of knowledge hardware nodes, supervise algorithm execution across knowledge hardware nodes, and collate and present results of analysis of the seemingly infinite actor population.",
  "publication_number": "US20180082192A1-20180322",
  "summary": "<SOH> SUMMARY OF THE INVENTION <EOH>Thus according to one aspect of the present design, there is provided a system comprising a series of interconnected compute servers comprising a supervisory hardware node and a plurality of knowledge hardware nodes, wherein the series of interconnected compute servers are configured to categorize and scale performance of multiple disjoint algorithms across a seemingly infinite actor population, wherein the series of interconnected compute servers are configured to normalize data using a common taxonomy, distribute normalized data relatively evenly across the plurality of knowledge hardware nodes, supervise algorithm execution across knowledge hardware nodes, and collate and present results of analysis of the seemingly infinite actor population. According to a further aspect of the present design, there is provided a system comprising a knowledge base system comprising a rule package comprising a plurality of rule sets, and a relevancy processor arrangement comprising a series of processors organized in a tree arrangement and configured to perform functions according to at least one of the plurality of rule sets contained in the rule package, wherein a topmost processor in the tree structure provides results of analysis using fuzzy logic. The relevancy processor arrangement comprises a series of interconnected compute servers comprising aggregator hardware nodes and processor hardware nodes, wherein the series of interconnected compute servers are configured to categorize and scale performance of multiple disjoint algorithms across a seemingly infinite actor population. The series of interconnected compute servers are configured to normalize data using a common taxonomy. According to a further aspect of the present design, there is provided a system comprising a knowledge base hardware system comprising a rule package comprising a plurality of rule sets configured to receive rules from a rule device and events from an events devic...",
  "ipcr_labels": [
    "G06N502",
    "G06F1518",
    "G06N304",
    "G06F1730"
  ],
  "inventor_list": [
    {
      "inventor_name_last": "Cormier",
      "inventor_name_first": "Michael E.",
      "inventor_city": "Delray Beach",
      "inventor_state": "FL",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Cox",
      "inventor_name_first": "Earl D.",
      "inventor_city": "Delray Beach",
      "inventor_state": "FL",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Thackrey",
      "inventor_name_first": "William E.",
      "inventor_city": "Delray Beach",
      "inventor_state": "FL",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "McGlynn",
      "inventor_name_first": "Joseph",
      "inventor_city": "Delray Beach",
      "inventor_state": "FL",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Gardner",
      "inventor_name_first": "Harry",
      "inventor_city": "Delray Beach",
      "inventor_state": "FL",
      "inventor_country": "US"
    }
  ],
  "title": "COGNITIVE MODELING APPARATUS INCLUDING MULTIPLE KNOWLEDGE NODE AND SUPERVISORY NODE DEVICES",
  "decision": "PENDING",
  "_processing_info": {
    "original_size": 169699,
    "optimized_size": 3926,
    "reduction_percent": 97.69
  }
}