{
  "date_produced": "20170719",
  "publication_number": "US20170220949A1-20170803",
  "main_ipcr_label": "G06N9900",
  "decision": "PENDING",
  "application_number": "15009968",
  "inventor_list": [
    {
      "inventor_name_last": "Feng",
      "inventor_name_first": "Andrew",
      "inventor_city": "Cupertino",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Shi",
      "inventor_name_first": "Jun",
      "inventor_city": "Sunnyvale",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Jain",
      "inventor_name_first": "Mridul",
      "inventor_city": "Cupertino",
      "inventor_state": "CA",
      "inventor_country": "US"
    },
    {
      "inventor_name_last": "Cnudde",
      "inventor_name_first": "Peter",
      "inventor_city": "Los Altos",
      "inventor_state": "CA",
      "inventor_country": "US"
    }
  ],
  "abstract": "The present teaching relates to distributed deep machine learning on a cluster. In one example, a request is received for estimating one or more parameters associated with a machine learning model on a cluster including a plurality of nodes. A set of data is obtained to be used for estimating the one or more parameters. The set of data is divided into a plurality of sub-sets of data, each of which corresponds to one of the plurality of nodes. Each sub-set of data is allocated to a corresponding node for estimating values of the one or more parameters based on the sub-set of data. Estimated values of the one or more parameters obtained based on a corresponding sub-set of data allocated to the node, are received from each of the plurality of nodes. The one or more parameters of the machine learning model are estimated based on the estimated values of the one or more parameters generated by at least some of the plurality of nodes.",
  "filing_date": "20160129",
  "patent_number": "None",
  "summary": "<SOH> SUMMARY <EOH>The present teaching relates to methods, systems, and programming for distributed computing. Particularly, the present teaching is directed to methods, systems, and programming for distributed deep machine learning on a cluster. In one example, a method, implemented on a machine having at least one processor, storage, and a communication platform capable of connecting to a network for estimating one or more parameters on a cluster including a plurality of nodes, is disclosed. A request is received for estimating one or more parameters associated with a machine learning model. A set of data is obtained to be used for estimating the one or more parameters. The set of data is divided into a plurality of sub-sets of data, each of which corresponds to one of the plurality of nodes. Each sub-set of data is allocated to a corresponding node for estimating values of the one or more parameters based on the sub-set of data. Estimated values of the one or more parameters obtained based on a corresponding sub-set of data allocated to the node, are received from each of the plurality of nodes. The one or more parameters of the machine learning model are estimated based on the estimated values of the one or more parameters generated by at least some of the plurality of nodes. In another example, a system having at least one processor, storage, and a communication platform connected to a network for estimating one or more parameters on a cluster including a plurality of nodes is disclosed. The system comprises: a configuration information identifier configured for receiving a request for estimating one or more parameters associated with a machine learning model; a training data locator configured for obtaining a set of data to be used for estimating the one or more parameters; a training data distributor configured for dividing the set of data into a plurality of sub-sets of data, each of which corresponds to one of the plurality of nodes and allocating each sub...",
  "date_published": "20170803",
  "title": "METHOD AND SYSTEM FOR DISTRIBUTED DEEP MACHINE LEARNING",
  "ipcr_labels": [
    "G06N9900"
  ],
  "_processing_info": {
    "original_size": 80740,
    "optimized_size": 3917,
    "reduction_percent": 95.15
  }
}